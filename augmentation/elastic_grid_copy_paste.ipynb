{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8ae767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 00:19:45,628 - INFO - \n",
      "\n",
      "==================== 단일 증강 실험 시작 ====================\n",
      "2025-06-07 00:19:45,630 - INFO - 파이프라인 유형: elastic_grid_first\n",
      "2025-06-07 00:19:45,631 - INFO - 블렌드 모드: simple_alpha\n",
      "2025-06-07 00:19:45,631 - INFO - 출력 폴더: C:\\Users\\USER\\Desktop\\증강(cutout+elastic)\\augmented_output\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 914\u001b[0m\n\u001b[0;32m    909\u001b[0m output_dir_single_exp \u001b[38;5;241m=\u001b[39m Path(output_dir_path_base) \n\u001b[0;32m    910\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m출력 폴더: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir_single_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    912\u001b[0m pipeline_single \u001b[38;5;241m=\u001b[39m OptimizedYOLOAugmentation(\n\u001b[0;32m    913\u001b[0m     images_dir\u001b[38;5;241m=\u001b[39mimages_dir_path, labels_dir\u001b[38;5;241m=\u001b[39mlabels_dir_path,\n\u001b[1;32m--> 914\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(output_dir_single_exp), class_names\u001b[38;5;241m=\u001b[39mclass_names\n\u001b[0;32m    915\u001b[0m )\n\u001b[0;32m    916\u001b[0m pipeline_single\u001b[38;5;241m.\u001b[39maugment_dataset_pipeline(\n\u001b[0;32m    917\u001b[0m     pipeline_type\u001b[38;5;241m=\u001b[39mchosen_pipeline_type, \n\u001b[0;32m    918\u001b[0m     target_total_images\u001b[38;5;241m=\u001b[39mtarget_total_images_for_experiment, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     blend_mode\u001b[38;5;241m=\u001b[39mchosen_blend_mode \n\u001b[0;32m    923\u001b[0m )\n\u001b[0;32m    925\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m단일 증강 실험 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_pipeline_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_blend_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys \n",
    "import matplotlib.font_manager as fm\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 한글 폰트 설정 함수  ---\n",
    "def set_korean_font():\n",
    "    \"\"\"Matplotlib에 한글 폰트를 설정합니다.\"\"\"\n",
    "    try:\n",
    "        if sys.platform == \"win32\":  # Windows\n",
    "            font_name = None\n",
    "            available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "            if 'Malgun Gothic' in available_fonts:\n",
    "                font_name = 'Malgun Gothic'\n",
    "            else: \n",
    "                font_path_win = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "                if os.path.exists(font_path_win):\n",
    "                    try:\n",
    "                        font_prop = fm.FontProperties(fname=font_path_win)\n",
    "                        font_name = font_prop.get_name()\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Windows malgun.ttf 파일에서 폰트 이름 가져오기 실패: {e}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Windows에서 'Malgun Gothic' 폰트를 찾을 수 없습니다. 경로: {font_path_win}\")\n",
    "            \n",
    "            if font_name:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Windows에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            else:\n",
    "                logger.error(\"Windows에서 한글 폰트를 설정하지 못했습니다. 시각화 시 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "        elif sys.platform == \"darwin\":  # macOS\n",
    "            font_name = 'AppleGothic' \n",
    "            try:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"macOS에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            except RuntimeError: \n",
    "                logger.warning(f\"macOS에서 '{font_name}' 폰트를 찾을 수 없습니다. 다른 한글 폰트를 확인해주세요.\")\n",
    "\n",
    "        elif sys.platform.startswith(\"linux\"):  # Linux\n",
    "            font_path_linux = None\n",
    "            nanum_fonts = [f for f in fm.fontManager.ttflist if 'NanumGothic' in f.name]\n",
    "            if nanum_fonts:\n",
    "                font_path_linux = nanum_fonts[0].fname \n",
    "                font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "            else: \n",
    "                font_paths_linux_fallback = [\n",
    "                    \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\",\n",
    "                    \"/usr/share/fonts/nanum/NanumGothic.ttf\",\n",
    "                ]\n",
    "                for path_option in font_paths_linux_fallback:\n",
    "                    if os.path.exists(path_option):\n",
    "                        font_path_linux = path_option\n",
    "                        break\n",
    "                if font_path_linux:\n",
    "                    font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                    plt.rc(\"font\", family=font_name)\n",
    "                    logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "                else:\n",
    "                    logger.error(\"Linux에서 NanumGothic 폰트를 찾을 수 없습니다. 'sudo apt-get install fonts-nanum*'으로 설치해주세요.\")\n",
    "        else:\n",
    "            logger.warning(f\"지원되지 않는 OS 플랫폼({sys.platform})입니다. 한글 폰트가 제대로 설정되지 않을 수 있습니다.\")\n",
    "        plt.rc(\"axes\", unicode_minus=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"한글 폰트 설정 중 오류 발생: {e}\")\n",
    "        logger.warning(\"기본 폰트로 시도합니다. 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "class AdvancedBlending:\n",
    "    \"\"\"정교한 블렌딩 기법을 적용한 Copy-Paste\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def feather_edges(mask, feather_amount=10):\n",
    "        \"\"\"마스크 가장자리를 부드럽게 페더링\"\"\"\n",
    "        if mask is None or mask.size == 0:\n",
    "            logger.warning(\"페더링할 마스크가 비어있습니다.\")\n",
    "            return mask\n",
    "        if np.all(mask == 0): \n",
    "            return mask.astype(float) \n",
    "            \n",
    "        binary_mask = (mask > 0).astype(np.uint8) \n",
    "        dist_transform = distance_transform_edt(binary_mask)\n",
    "        feather_amount_safe = max(feather_amount, 1e-5)\n",
    "        feathered = np.minimum(dist_transform / feather_amount_safe, 1.0)\n",
    "        return feathered\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_blend(obj_img, background, obj_binary_mask, center_coords):\n",
    "        \"\"\"포아송 블렌딩 (Seamless Cloning)\"\"\"\n",
    "        if obj_img is None or obj_img.size == 0: return background\n",
    "        if background is None or background.size == 0: return background\n",
    "        if obj_binary_mask is None or obj_binary_mask.size == 0: return background\n",
    "\n",
    "        mask_for_poisson = (obj_binary_mask > 0).astype(np.uint8) * 255\n",
    "        \n",
    "        if np.sum(mask_for_poisson) == 0:\n",
    "            logger.warning(\"포아송 블렌딩을 위한 마스크가 비어있습니다. 원본 배경을 반환합니다.\")\n",
    "            return background.copy()\n",
    "\n",
    "        try:\n",
    "            # seamlessClone은 입력 이미지와 마스크의 크기가 같아야 함\n",
    "            if obj_img.shape[:2] != mask_for_poisson.shape[:2]:\n",
    "                logger.warning(f\"Poisson Blend: 객체 이미지({obj_img.shape[:2]})와 마스크({mask_for_poisson.shape[:2]}) 크기가 다릅니다. 마스크를 객체 크기로 조정합니다.\")\n",
    "                mask_for_poisson = cv2.resize(mask_for_poisson, (obj_img.shape[1], obj_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # center_coords가 이미지 경계 내에 있는지 확인 및 조정\n",
    "            h_bg, w_bg = background.shape[:2]\n",
    "            h_obj, w_obj = obj_img.shape[:2]\n",
    "            \n",
    "            if not (0 <= center_coords[0] < w_bg and 0 <= center_coords[1] < h_bg):\n",
    "                logger.error(f\"Poisson Blend: 중심점 {center_coords}이 배경 크기 {background.shape[:2]} 밖에 있습니다.\")\n",
    "                return background.copy()\n",
    "\n",
    "\n",
    "            result = cv2.seamlessClone(\n",
    "                obj_img, \n",
    "                background, \n",
    "                mask_for_poisson, \n",
    "                center_coords, \n",
    "                cv2.NORMAL_CLONE \n",
    "            )\n",
    "            return result\n",
    "        except cv2.error as e:\n",
    "            logger.error(f\"포아송 블렌딩 오류: {e}. 객체 크기: {obj_img.shape}, 마스크 크기: {mask_for_poisson.shape}, 배경 크기: {background.shape}, 중심: {center_coords}\")\n",
    "            return background.copy()\n",
    "\n",
    "    @staticmethod\n",
    "    def multiband_blend(background_roi, obj_img_aligned, obj_mask_aligned_0_1_float_3ch, levels=4):\n",
    "        \"\"\"멀티밴드 블렌딩 (Laplacian Pyramid)\"\"\"\n",
    "        if background_roi is None or obj_img_aligned is None or obj_mask_aligned_0_1_float_3ch is None or \\\n",
    "           background_roi.size == 0 or obj_img_aligned.size == 0 or obj_mask_aligned_0_1_float_3ch.size == 0:\n",
    "            logger.warning(\"멀티밴드 블렌딩 입력값이 유효하지 않습니다.\")\n",
    "            return background_roi \n",
    "        \n",
    "        if background_roi.shape != obj_img_aligned.shape or background_roi.shape != obj_mask_aligned_0_1_float_3ch.shape:\n",
    "            logger.warning(\"멀티밴드 블렌딩: 입력 이미지/마스크 크기가 일치하지 않습니다.\")\n",
    "            return background_roi\n",
    "\n",
    "\n",
    "        gpA = [background_roi.astype(np.float32)] \n",
    "        gpB = [obj_img_aligned.astype(np.float32)] \n",
    "        gpM = [obj_mask_aligned_0_1_float_3ch.astype(np.float32)] \n",
    "\n",
    "        current_levels = 0\n",
    "        for i in range(levels):\n",
    "            if gpA[i].shape[0] < 2 or gpA[i].shape[1] < 2 or \\\n",
    "               gpB[i].shape[0] < 2 or gpB[i].shape[1] < 2 or \\\n",
    "               gpM[i].shape[0] < 2 or gpM[i].shape[1] < 2:\n",
    "                logger.warning(f\"멀티밴드 블렌딩 중 피라미드 레벨 {i+1}에서 이미지 크기가 너무 작아 현재 레벨({i})까지만 처리합니다.\")\n",
    "                levels = i \n",
    "                break\n",
    "            gpA.append(cv2.pyrDown(gpA[i]))\n",
    "            gpB.append(cv2.pyrDown(gpB[i]))\n",
    "            gpM.append(cv2.pyrDown(gpM[i]))\n",
    "            current_levels +=1\n",
    "        \n",
    "        if current_levels == 0 and levels > 0 : \n",
    "             logger.warning(\"멀티밴드 블렌딩: 이미지 크기가 너무 작아 피라미드를 생성할 수 없습니다. 단순 알파 블렌딩으로 대체합니다.\")\n",
    "             blended_roi_content = background_roi * (1 - obj_mask_aligned_0_1_float_3ch) + obj_img_aligned * obj_mask_aligned_0_1_float_3ch\n",
    "             return np.clip(blended_roi_content, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        lpA = [gpA[levels]]\n",
    "        lpB = [gpB[levels]]\n",
    "        for i in range(levels, 0, -1):\n",
    "            size = (gpA[i-1].shape[1], gpA[i-1].shape[0])\n",
    "            lpA.append(cv2.subtract(gpA[i-1], cv2.pyrUp(gpA[i], dstsize=size)))\n",
    "            lpB.append(cv2.subtract(gpB[i-1], cv2.pyrUp(gpB[i], dstsize=size)))\n",
    "        \n",
    "        LS = []\n",
    "        for i in range(levels + 1): \n",
    "            la_current = lpA[i]\n",
    "            lb_current = lpB[i]\n",
    "            gm_current = gpM[levels-i] \n",
    "            \n",
    "            if la_current.shape != gm_current.shape or lb_current.shape != gm_current.shape:\n",
    "                logger.warning(f\"멀티밴드 블렌드 중 레벨 {levels-i}에서 크기 불일치. 마스크 크기 조정 시도.\")\n",
    "                gm_current = cv2.resize(gm_current, (la_current.shape[1], la_current.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "                if gm_current.ndim == 2 and la_current.ndim == 3: \n",
    "                    gm_current = np.stack([gm_current]*3, axis=-1)\n",
    "\n",
    "            ls = la_current * (1.0 - gm_current) + lb_current * gm_current\n",
    "            LS.append(ls)\n",
    "        \n",
    "        ls_ = LS[0] \n",
    "        for i in range(1, levels + 1): \n",
    "            size = (LS[i].shape[1], LS[i].shape[0])\n",
    "            ls_ = cv2.add(cv2.pyrUp(ls_, dstsize=size), LS[i])\n",
    "        \n",
    "        return np.clip(ls_, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def blend_object_onto_background(self, background_orig, obj_img_transformed, obj_mask_transformed_binary, \n",
    "                                     obj_points_transformed_abs, paste_x, paste_y, new_w, new_h,\n",
    "                                     blend_mode='advanced_alpha'):\n",
    "        output_image = background_orig.copy()\n",
    "        y_start, y_end = int(paste_y), int(paste_y + new_h)\n",
    "        x_start, x_end = int(paste_x), int(paste_x + new_w)\n",
    "\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        if y_start < 0 or x_start < 0 or y_end > h_bg or x_end > w_bg:\n",
    "            logger.error(f\"블렌딩 ROI가 이미지 경계를 벗어납니다. ROI: ({x_start},{y_start})-({x_end},{y_end}), BG: ({w_bg},{h_bg})\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        roi_background = output_image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        if obj_img_transformed is None or obj_img_transformed.size == 0 or \\\n",
    "           obj_mask_transformed_binary is None or obj_mask_transformed_binary.size == 0:\n",
    "            logger.warning(\"블렌딩할 객체 이미지 또는 마스크가 비어있습니다.\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        if roi_background.shape[:2] != obj_img_transformed.shape[:2]:\n",
    "            logger.debug(f\"블렌딩 전 ROI({roi_background.shape[:2]})와 객체({obj_img_transformed.shape[:2]}) 크기 불일치. 객체/마스크를 ROI 크기로 조정.\")\n",
    "            obj_img_transformed = cv2.resize(obj_img_transformed, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            obj_mask_transformed_binary = cv2.resize(obj_mask_transformed_binary, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "        harmonized_obj_img = obj_img_transformed.copy()\n",
    "        if blend_mode in ['advanced_alpha', 'color_match_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "            try:\n",
    "                obj_lab = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                roi_lab = cv2.cvtColor(roi_background, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                obj_pixels_lab = obj_lab[obj_mask_transformed_binary > 0]\n",
    "                if obj_pixels_lab.size > 0:\n",
    "                    obj_mean = np.mean(obj_pixels_lab, axis=0); obj_std = np.std(obj_pixels_lab, axis=0)\n",
    "                    roi_mean = np.mean(roi_lab, axis=(0, 1)); roi_std = np.std(roi_lab, axis=(0, 1))\n",
    "                    for i in range(3):\n",
    "                        obj_lab[:, :, i] = np.clip(\n",
    "                            (obj_lab[:, :, i] - obj_mean[i]) * (roi_std[i] / (obj_std[i] + 1e-5)) + roi_mean[i],\n",
    "                            0, 255 \n",
    "                        )\n",
    "                    harmonized_obj_img = cv2.cvtColor(obj_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "                else: logger.debug(\"색상 조화를 위한 객체 픽셀이 없습니다.\")\n",
    "            except cv2.error as e: logger.warning(f\"색상 조화 중 OpenCV 오류: {e}\")\n",
    "\n",
    "            if blend_mode in ['advanced_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "                try:\n",
    "                    roi_gray = cv2.cvtColor(roi_background, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_gray = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_pixels_gray = obj_gray[obj_mask_transformed_binary > 0]\n",
    "                    if obj_pixels_gray.size > 0 and np.mean(obj_pixels_gray) > 1e-5 :\n",
    "                        brightness_ratio = np.mean(roi_gray) / (np.mean(obj_pixels_gray) + 1e-5)\n",
    "                        brightness_ratio = np.clip(brightness_ratio, 0.7, 1.5) \n",
    "                        harmonized_obj_img = cv2.convertScaleAbs(harmonized_obj_img, alpha=brightness_ratio, beta=0)\n",
    "                    else: logger.debug(\"조명 조화를 위한 객체 픽셀이 없거나 평균 밝기가 0에 가깝습니다.\")\n",
    "                except cv2.error as e: logger.warning(f\"조명 조화 중 OpenCV 오류: {e}\")\n",
    "        \n",
    "        if blend_mode == 'poisson' or blend_mode == 'poisson_harmonized':\n",
    "            center_in_bg_abs = (x_start + new_w // 2, y_start + new_h // 2)\n",
    "            output_image = self.poisson_blend(harmonized_obj_img, output_image, obj_mask_transformed_binary, center_in_bg_abs)\n",
    "        \n",
    "        elif blend_mode == 'multiband' or blend_mode == 'multiband_harmonized':\n",
    "            mask_0_1_float_3ch = np.stack([obj_mask_transformed_binary.astype(float)/255.0]*3, axis=-1)\n",
    "            blended_roi_content = self.multiband_blend(roi_background, harmonized_obj_img, mask_0_1_float_3ch)\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content\n",
    "\n",
    "        else: \n",
    "            if blend_mode == 'simple_alpha':\n",
    "                alpha_mask_0_1_float = cv2.GaussianBlur(obj_mask_transformed_binary, (5,5), 0).astype(float) / 255.0\n",
    "            else: \n",
    "                feather_amount = max(3, int(min(new_h, new_w) * 0.03)) \n",
    "                mask_feathered = self.feather_edges(obj_mask_transformed_binary, feather_amount)\n",
    "                blur_ksize = max(3, 2 * int(min(new_h, new_w) * 0.02) + 1) \n",
    "                mask_blur = cv2.GaussianBlur(mask_feathered, (blur_ksize, blur_ksize), 0)\n",
    "                final_alpha_mask_0_1_float = np.clip(mask_blur, 0, 1)\n",
    "                if blend_mode == 'advanced_alpha':\n",
    "                    grad_x = cv2.Sobel(mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "                    grad_y = cv2.Sobel(mask_blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "                    gradient = np.sqrt(grad_x**2 + grad_y**2)\n",
    "                    if np.max(gradient) > 1e-5:\n",
    "                        gradient = gradient / np.max(gradient)\n",
    "                        final_alpha_mask_0_1_float = final_alpha_mask_0_1_float * (1 - gradient * 0.2) \n",
    "                        final_alpha_mask_0_1_float = np.clip(final_alpha_mask_0_1_float, 0, 1)\n",
    "                alpha_mask_0_1_float = final_alpha_mask_0_1_float\n",
    "\n",
    "            alpha_mask_3ch = np.stack([alpha_mask_0_1_float] * 3, axis=-1)\n",
    "            blended_roi_content = roi_background * (1 - alpha_mask_3ch) + harmonized_obj_img * alpha_mask_3ch\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content.astype(np.uint8)\n",
    "\n",
    "            if blend_mode == 'advanced_alpha':\n",
    "                try:\n",
    "                    shadow_kernel_size = max(3, int(min(new_h, new_w) * 0.08)) \n",
    "                    shadow_kernel_size = shadow_kernel_size if shadow_kernel_size % 2 != 0 else shadow_kernel_size + 1 \n",
    "                    dilated_mask = cv2.dilate(obj_mask_transformed_binary, np.ones((shadow_kernel_size//2, shadow_kernel_size//2), np.uint8), iterations=1)\n",
    "                    shadow_alpha_mask = cv2.GaussianBlur(dilated_mask, (shadow_kernel_size, shadow_kernel_size), 0)\n",
    "                    shadow_alpha_mask = shadow_alpha_mask.astype(float) / 255.0 * 0.15 \n",
    "                    shadow_region_float = output_image[y_start:y_end, x_start:x_end].astype(float)\n",
    "                    effective_shadow_alpha = np.clip(shadow_alpha_mask - (obj_mask_transformed_binary.astype(float)/255.0), 0, 1)\n",
    "                    for c in range(3):\n",
    "                        shadow_region_float[:,:,c] *= (1 - effective_shadow_alpha * 0.7) \n",
    "                    output_image[y_start:y_end, x_start:x_end] = np.clip(shadow_region_float, 0, 255).astype(np.uint8)\n",
    "                except Exception as e: logger.warning(f\"그림자 효과 적용 중 오류: {e}\")\n",
    "        return output_image, obj_points_transformed_abs\n",
    "\n",
    "\n",
    "class OptimizedYOLOAugmentation:\n",
    "    def __init__(self, images_dir, labels_dir, output_dir, class_names=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_images_dir = self.output_dir / 'images'\n",
    "        self.output_labels_dir = self.output_dir / 'labels'\n",
    "        self.output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.class_names = class_names or ['ac', 'lc', 'pc', 'tc', 'ph']\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "        self.class_objects = defaultdict(list)\n",
    "        self.original_class_counts = Counter()\n",
    "        self.augmented_class_counts = Counter() # 이 카운터는 visualize 시점에 최종 폴더를 분석하여 채워짐\n",
    "        self.min_object_size = 30\n",
    "        self.max_object_ratio = 0.4\n",
    "        self.blender = AdvancedBlending()\n",
    "\n",
    "    def analyze_dataset(self):\n",
    "        logger.info(\"데이터셋 분석 중...\")\n",
    "        self.original_class_counts.clear()\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다.\")\n",
    "            return self.original_class_counts\n",
    "        total_images_processed = 0\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    total_images_processed +=1\n",
    "                    for shape in data['shapes']:\n",
    "                        if 'label' in shape and shape['label'] in self.class_to_idx:\n",
    "                            self.original_class_counts[shape['label']] += 1\n",
    "                        elif 'label' in shape:\n",
    "                            logger.warning(f\"라벨 파일 '{json_file.name}'에 정의되지 않은 클래스 '{shape['label']}'가 있습니다.\")\n",
    "            except json.JSONDecodeError: logger.error(f\"JSON 파싱 오류: {json_file}\")\n",
    "            except Exception as e: logger.error(f\"파일 분석 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {total_images_processed}개의 이미지 라벨 분석 완료.\")\n",
    "        logger.info(f\"원본 클래스별 분포: {dict(self.original_class_counts)}\")\n",
    "        return self.original_class_counts\n",
    "    \n",
    "    def calculate_optimized_weights(self):\n",
    "        if not self.original_class_counts:\n",
    "            logger.warning(\"원본 클래스 카운트가 없어 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        total_objects = sum(self.original_class_counts.values())\n",
    "        # 객체가 있는 클래스 수만 계산\n",
    "        num_classes_with_objects = len([c_name for c_name, count in self.original_class_counts.items() if count > 0])\n",
    "\n",
    "        if total_objects == 0 or num_classes_with_objects == 0:\n",
    "            logger.warning(\"객체가 없거나 객체가 있는 클래스가 없어 유효한 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        \n",
    "        weights = {}\n",
    "        for class_name in self.class_names: # 모든 정의된 클래스에 대해\n",
    "            count = self.original_class_counts.get(class_name, 0)\n",
    "            if count > 0: \n",
    "                weight = np.sqrt(total_objects / (num_classes_with_objects * count))\n",
    "            else: \n",
    "                weight = 0 # 객체 없는 클래스는 일단 0\n",
    "            weights[class_name] = weight\n",
    "        \n",
    "        # 객체가 없는 클래스에 대한 가중치 후처리 (다른 클래스 최대 가중치의 1.5배)\n",
    "        valid_weights = [w for w in weights.values() if w > 0]\n",
    "        max_calculated_weight = max(valid_weights) if valid_weights else 1.0 # 유효한 가중치가 없으면 기본값 1.0\n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            if weights[class_name] == 0: \n",
    "                 weights[class_name] = max_calculated_weight * 1.5 \n",
    "        \n",
    "        logger.info(f\"최적화된 증강 가중치: {weights}\")\n",
    "        return weights\n",
    "\n",
    "    def intelligent_copy_paste_with_advanced_blending(self, background_orig, \n",
    "                                                     class_weights, \n",
    "                                                     num_pastes_range=(1, 4), \n",
    "                                                     difficulty_level='medium',\n",
    "                                                     blend_mode='advanced_alpha'):\n",
    "        if not any(self.class_objects.values()):\n",
    "            logger.warning(\"Copy-Paste를 위한 추출된 객체가 없습니다.\")\n",
    "            return background_orig, [] \n",
    "\n",
    "        output_image = background_orig.copy()\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        pasted_shapes_info = [] \n",
    "\n",
    "        min_pastes, max_pastes = num_pastes_range\n",
    "        if difficulty_level == 'easy':\n",
    "            num_pastes_actual = random.randint(min_pastes, max(min_pastes, (min_pastes + max_pastes) // 3))\n",
    "        elif difficulty_level == 'medium':\n",
    "            num_pastes_actual = random.randint(min_pastes, max_pastes)\n",
    "        else: \n",
    "            num_pastes_actual = random.randint(max_pastes, int(max_pastes * 1.5))\n",
    "            num_pastes_actual = min(num_pastes_actual, 8) \n",
    "        \n",
    "        if not class_weights or not any(v > 0 for v in class_weights.values()):\n",
    "            logger.warning(\"유효한 클래스 가중치가 없어 Copy-Paste를 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return output_image, []\n",
    "\n",
    "        classes_with_objects_and_weights = [cn for cn in class_weights if class_weights.get(cn, 0) > 0 and self.class_objects.get(cn)]\n",
    "        if not classes_with_objects_and_weights:\n",
    "            logger.warning(\"붙여넣을 수 있는 객체가 있는 클래스가 없거나 가중치가 없습니다.\")\n",
    "            return output_image, []\n",
    "        weights_for_choice = [class_weights[cn] for cn in classes_with_objects_and_weights]\n",
    "\n",
    "        occupied_bboxes = [] \n",
    "        successfully_pasted_count = 0\n",
    "\n",
    "        for _ in range(num_pastes_actual):\n",
    "            try:\n",
    "                selected_class = random.choices(classes_with_objects_and_weights, weights=weights_for_choice)[0]\n",
    "            except IndexError:\n",
    "                logger.warning(\"가중치 기반 클래스 선택 실패. 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "                continue\n",
    "            \n",
    "            if not self.class_objects[selected_class]: continue\n",
    "\n",
    "            obj_data = random.choice(self.class_objects[selected_class])\n",
    "            obj_img_to_paste = obj_data['image'] \n",
    "            obj_mask_to_paste = obj_data['mask'] \n",
    "            obj_points_relative = obj_data['points'].copy() \n",
    "\n",
    "            if obj_img_to_paste is None or obj_img_to_paste.size == 0 or \\\n",
    "               obj_mask_to_paste is None or obj_mask_to_paste.size == 0:\n",
    "                logger.warning(f\"선택된 객체 '{selected_class}'의 이미지 또는 마스크가 비어있습니다.\")\n",
    "                continue\n",
    "\n",
    "            h_obj_orig, w_obj_orig = obj_img_to_paste.shape[:2]\n",
    "\n",
    "            current_scale = random.uniform(0.6, 1.4)\n",
    "            current_rotation = 0\n",
    "            if random.random() < 0.4: current_rotation = random.uniform(-20, 20)\n",
    "            \n",
    "            transform_center = (w_obj_orig // 2, h_obj_orig // 2)\n",
    "            M_transform = cv2.getRotationMatrix2D(transform_center, current_rotation, current_scale)\n",
    "            \n",
    "            cos_t = np.abs(M_transform[0, 0]); sin_t = np.abs(M_transform[0, 1])\n",
    "            new_obj_w = int((h_obj_orig * sin_t) + (w_obj_orig * cos_t))\n",
    "            new_obj_h = int((h_obj_orig * cos_t) + (w_obj_orig * sin_t))\n",
    "\n",
    "            if new_obj_w == 0 or new_obj_h == 0: continue\n",
    "\n",
    "            M_transform[0, 2] += (new_obj_w / 2) - transform_center[0]\n",
    "            M_transform[1, 2] += (new_obj_h / 2) - transform_center[1]\n",
    "            \n",
    "            final_obj_img = cv2.warpAffine(obj_img_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "            final_obj_mask_binary = cv2.warpAffine(obj_mask_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=(0))\n",
    "            \n",
    "            ones_homo = np.ones((obj_points_relative.shape[0], 1))\n",
    "            points_homo = np.hstack([obj_points_relative, ones_homo])\n",
    "            final_obj_points_relative_transformed = (M_transform @ points_homo.T).T \n",
    "\n",
    "            if new_obj_h >= h_bg or new_obj_w >= w_bg: continue\n",
    "            \n",
    "            if random.random() < 0.3: \n",
    "                color_aug = A.Compose([\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=1.0),\n",
    "                    A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=18, val_shift_limit=12, p=1.0)\n",
    "                ])\n",
    "                final_obj_img = color_aug(image=final_obj_img)['image']\n",
    "\n",
    "            paste_margin = max(5, int(0.01 * min(h_bg, w_bg)))\n",
    "            if w_bg - new_obj_w - 2 * paste_margin <= 0 or h_bg - new_obj_h - 2 * paste_margin <= 0: continue\n",
    "            \n",
    "            found_position = False\n",
    "            for _ in range(30): \n",
    "                current_paste_x = random.randint(paste_margin, w_bg - new_obj_w - paste_margin)\n",
    "                current_paste_y = random.randint(paste_margin, h_bg - new_obj_h - paste_margin)\n",
    "                current_bbox_abs = [current_paste_x, current_paste_y, current_paste_x + new_obj_w, current_paste_y + new_obj_h]\n",
    "                \n",
    "                if any(self.calculate_iou(current_bbox_abs, occ_bbox) > 0.15 for occ_bbox in occupied_bboxes):\n",
    "                    continue\n",
    "                \n",
    "                output_image, _ = self.blender.blend_object_onto_background(\n",
    "                    output_image, final_obj_img, final_obj_mask_binary, \n",
    "                    None, \n",
    "                    current_paste_x, current_paste_y, new_obj_w, new_obj_h,\n",
    "                    blend_mode=blend_mode\n",
    "                )\n",
    "                \n",
    "                abs_points_for_label = (final_obj_points_relative_transformed + np.array([current_paste_x, current_paste_y])).astype(np.int32).tolist()\n",
    "                pasted_shapes_info.append({\n",
    "                    'label': selected_class,\n",
    "                    'points': abs_points_for_label, \n",
    "                    'group_id': None, 'shape_type': 'polygon', 'flags': {}\n",
    "                })\n",
    "                occupied_bboxes.append(current_bbox_abs)\n",
    "                successfully_pasted_count += 1\n",
    "                found_position = True\n",
    "                break\n",
    "        \n",
    "        logger.debug(f\"{successfully_pasted_count}개의 객체(Advanced Blending) 붙여넣기 완료 (시도: {num_pastes_actual}개).\")\n",
    "        return output_image, pasted_shapes_info\n",
    "    \n",
    "    def apply_geometric_transform(self, image, shapes, transform_prob=0.8):\n",
    "        \"\"\"\n",
    "        이미지와 모든 shape의 폴리곤 좌표에 동일한 기하 변형(Elastic, Grid)을 적용합니다.\n",
    "        shapes: [{'label': 'name', 'points': [[x1,y1], ...], ...}, ...]\n",
    "        \"\"\"\n",
    "        if random.random() >= transform_prob: \n",
    "            return image, shapes\n",
    "\n",
    "        transform_pipeline = A.Compose([\n",
    "            A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7, \n",
    "                               border_mode=cv2.BORDER_REFLECT_101),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7, \n",
    "                             border_mode=cv2.BORDER_REFLECT_101),\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['shape_indices'], remove_invisible=False))\n",
    "\n",
    "        all_keypoints_flat = []\n",
    "        keypoint_shape_indices = [] \n",
    "        points_per_shape_count = [] \n",
    "\n",
    "        for idx, shape_dict in enumerate(shapes):\n",
    "            points = shape_dict.get('points', [])\n",
    "            if points and len(points) >=3 : \n",
    "                all_keypoints_flat.extend(points) \n",
    "                keypoint_shape_indices.extend([idx] * len(points)) \n",
    "                points_per_shape_count.append(len(points))\n",
    "            else:\n",
    "                points_per_shape_count.append(0) \n",
    "\n",
    "        if not all_keypoints_flat: \n",
    "            img_only_transform_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7,\n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7,\n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_transform_pipeline(image=image)['image']\n",
    "            return transformed_image, shapes \n",
    "\n",
    "        try:\n",
    "            transformed_data = transform_pipeline(image=image, keypoints=all_keypoints_flat, shape_indices=keypoint_shape_indices)\n",
    "            transformed_image = transformed_data['image']\n",
    "            transformed_keypoints_flat = transformed_data['keypoints']\n",
    "\n",
    "            new_shapes = []\n",
    "            current_kp_idx = 0\n",
    "            for shape_idx, original_shape_dict in enumerate(shapes):\n",
    "                num_points_for_this_shape = points_per_shape_count[shape_idx]\n",
    "                new_shape = original_shape_dict.copy()\n",
    "                if num_points_for_this_shape > 0:\n",
    "                    shape_keypoints = transformed_keypoints_flat[current_kp_idx : current_kp_idx + num_points_for_this_shape]\n",
    "                    new_shape['points'] = np.array(shape_keypoints, dtype=np.int32).tolist()\n",
    "                    current_kp_idx += num_points_for_this_shape\n",
    "                else: \n",
    "                    new_shape['points'] = [] \n",
    "                new_shapes.append(new_shape)\n",
    "            \n",
    "            return transformed_image, new_shapes\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"기하 변형 중 오류 발생: {e}. 이미지 변형만 시도합니다.\")\n",
    "            img_only_transform_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=1.0, \n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=1.0, \n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_transform_pipeline(image=image)['image']\n",
    "            return transformed_image, shapes \n",
    "\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        x1_inter = max(box1[0], box2[0])\n",
    "        y1_inter = max(box1[1], box2[1])\n",
    "        x2_inter = min(box1[2], box2[2])\n",
    "        y2_inter = min(box1[3], box2[3])\n",
    "        intersection_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "        if intersection_area == 0: return 0.0\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union_area = area1 + area2 - intersection_area\n",
    "        return intersection_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "    def extract_objects_from_dataset(self):\n",
    "        logger.info(\"고품질 객체 추출 중...\")\n",
    "        self.class_objects.clear()\n",
    "        extracted_count = 0\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다. 객체 추출을 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        for idx, json_file in enumerate(json_files):\n",
    "            if idx % 50 == 0: logger.info(f\"객체 추출 진행: {idx}/{len(json_files)}\")\n",
    "            try:\n",
    "                base_name = json_file.stem\n",
    "                img_file, _ = self._find_image_file(base_name)\n",
    "                if not img_file:\n",
    "                    logger.warning(f\"객체 추출을 위한 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "                image = cv2.imread(str(img_file))\n",
    "                if image is None:\n",
    "                    logger.warning(f\"이미지 로드 실패: {img_file}\")\n",
    "                    continue\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' not in data: continue\n",
    "                for shape in data['shapes']:\n",
    "                    if shape.get('shape_type') != 'polygon' or 'label' not in shape: continue\n",
    "                    label = shape['label']\n",
    "                    if label not in self.class_to_idx:\n",
    "                        logger.debug(f\"객체 추출 중 정의되지 않은 라벨 '{label}' 발견: {json_file.name}\")\n",
    "                        continue\n",
    "                    points_list = shape.get('points', [])\n",
    "                    if not points_list or len(points_list) < 3: continue\n",
    "                    points = np.array(points_list, dtype=np.int32)\n",
    "                    x, y, w, h = cv2.boundingRect(points)\n",
    "                    if not (self.min_object_size <= w < image.shape[1] * self.max_object_ratio and \\\n",
    "                            self.min_object_size <= h < image.shape[0] * self.max_object_ratio):\n",
    "                        continue\n",
    "                    if h == 0: continue\n",
    "                    aspect_ratio = w / h\n",
    "                    if not (0.2 < aspect_ratio < 5.0): continue\n",
    "                    obj_region_mask_full = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "                    cv2.fillPoly(obj_region_mask_full, [points], 255)\n",
    "                    obj_img_cropped = image[y:y+h, x:x+w].copy()\n",
    "                    obj_mask_cropped = obj_region_mask_full[y:y+h, x:x+w].copy() \n",
    "                    obj_img_masked = cv2.bitwise_and(obj_img_cropped, obj_img_cropped, mask=obj_mask_cropped)\n",
    "                    relative_points = points - np.array([x, y])\n",
    "                    self.class_objects[label].append({\n",
    "                        'image': obj_img_masked,    \n",
    "                        'mask': obj_mask_cropped,   \n",
    "                        'points': relative_points,  \n",
    "                    })\n",
    "                    extracted_count += 1\n",
    "            except Exception as e: logger.exception(f\"객체 추출 중 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {extracted_count}개의 객체 추출 완료.\")\n",
    "        for class_name, objects in self.class_objects.items():\n",
    "            logger.info(f\"  - {class_name}: {len(objects)}개\")\n",
    "\n",
    "    def _find_image_file(self, base_name):\n",
    "        possible_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', \n",
    "                               '.JPG', '.JPEG', '.PNG', '.BMP', '.TIFF']\n",
    "        for ext in possible_extensions:\n",
    "            potential_file = self.images_dir / f\"{base_name}{ext}\"\n",
    "            if potential_file.exists():\n",
    "                return potential_file, ext\n",
    "        return None, None\n",
    "\n",
    "\n",
    "    def augment_dataset_pipeline(self, pipeline_type=\"copy_paste_first\", \n",
    "                                target_total_images=2400, \n",
    "                                elastic_grid_prob=0.8,\n",
    "                                copy_paste_prob=0.9, \n",
    "                                num_pastes_range=(1,3),\n",
    "                                blend_mode='advanced_alpha'):\n",
    "        logger.info(f\"'{pipeline_type}' (블렌드: {blend_mode}) 파이프라인으로 데이터셋 증강 시작: 목표 {target_total_images}장\")\n",
    "\n",
    "        self.analyze_dataset()\n",
    "        if not self.original_class_counts:\n",
    "            logger.error(\"원본 데이터셋 분석 실패. 증강 중단.\")\n",
    "            return\n",
    "\n",
    "        class_weights = self.calculate_optimized_weights()\n",
    "        if not class_weights:\n",
    "            logger.error(\"클래스 가중치 계산 실패. 증강 중단.\")\n",
    "            return\n",
    "        \n",
    "        self.extract_objects_from_dataset()\n",
    "\n",
    "        logger.info(\"원본 파일 복사 중...\")\n",
    "        json_files_original = list(self.labels_dir.glob('*.json'))\n",
    "        original_image_count = len(json_files_original)\n",
    "\n",
    "        for json_file_idx, json_file in enumerate(json_files_original):\n",
    "            if json_file_idx % 100 == 0:\n",
    "                 logger.info(f\"원본 파일 복사 진행: {json_file_idx}/{len(json_files_original)}\")\n",
    "            base_name = json_file.stem\n",
    "            img_file, img_ext_found = self._find_image_file(base_name)\n",
    "            if img_file:\n",
    "                try:\n",
    "                    shutil.copy2(img_file, self.output_images_dir / img_file.name)\n",
    "                    shutil.copy2(json_file, self.output_labels_dir / json_file.name)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"원본 파일 복사 실패: {img_file} 또는 {json_file} - {e}\")\n",
    "            else:\n",
    "                logger.warning(f\"원본 이미지 파일을 찾지 못해 복사하지 못했습니다: {self.images_dir / base_name}\")\n",
    "\n",
    "        current_total_images = original_image_count\n",
    "        generated_augmented_count = 0\n",
    "        \n",
    "        difficulty_levels = ['easy', 'medium', 'hard']\n",
    "        difficulty_probs = [0.3, 0.5, 0.2]\n",
    "\n",
    "        while current_total_images < target_total_images:\n",
    "            random.shuffle(json_files_original)\n",
    "            for json_file_orig in json_files_original:\n",
    "                if current_total_images >= target_total_images: break\n",
    "\n",
    "                base_name = json_file_orig.stem\n",
    "                img_file_orig, img_ext = self._find_image_file(base_name)\n",
    "\n",
    "                if not img_file_orig:\n",
    "                    logger.warning(f\"증강을 위한 원본 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    image = cv2.imread(str(img_file_orig))\n",
    "                    if image is None:\n",
    "                        logger.warning(f\"이미지 로드 실패: {img_file_orig}\")\n",
    "                        continue\n",
    "                    \n",
    "                    with open(json_file_orig, 'r', encoding='utf-8') as f:\n",
    "                        label_data = json.load(f)\n",
    "                    \n",
    "                    original_shapes = label_data.get('shapes', []) \n",
    "                    augmented_image = image.copy()\n",
    "                    current_shapes = [s.copy() for s in original_shapes] \n",
    "\n",
    "                    difficulty = random.choices(difficulty_levels, difficulty_probs)[0]\n",
    "\n",
    "                    if pipeline_type == \"copy_paste_first\": \n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights,\n",
    "                                num_pastes_range=num_pastes_range,\n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"CPF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                        \n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"CPF: Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "\n",
    "                    elif pipeline_type == \"elastic_grid_first\": \n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"EGF: Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights, \n",
    "                                num_pastes_range=num_pastes_range, \n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"EGF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                            \n",
    "                    else:\n",
    "                        logger.error(f\"알 수 없는 파이프라인 유형: {pipeline_type}\")\n",
    "                        continue\n",
    "                    \n",
    "                    current_shapes = [s for s in current_shapes if s.get('points') and len(s['points']) >= 3]\n",
    "\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "                    aug_base_name = f\"{base_name}_{pipeline_type}_{blend_mode}_{timestamp}_{random.randint(1000,9999)}\"\n",
    "                    aug_img_path = self.output_images_dir / f\"{aug_base_name}{img_ext}\" \n",
    "                    aug_label_path = self.output_labels_dir / f\"{aug_base_name}.json\"\n",
    "\n",
    "                    cv2.imwrite(str(aug_img_path), augmented_image)\n",
    "                    \n",
    "                    final_label_data = {\n",
    "                        \"version\": label_data.get(\"version\", \"5.0.0\"), \"flags\": label_data.get(\"flags\", {}),\n",
    "                        \"shapes\": current_shapes, \n",
    "                        \"imagePath\": aug_img_path.name, \"imageData\": None,\n",
    "                        \"imageHeight\": augmented_image.shape[0], \"imageWidth\": augmented_image.shape[1]\n",
    "                    }\n",
    "                    with open(aug_label_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(final_label_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    generated_augmented_count += 1\n",
    "                    current_total_images += 1\n",
    "                    if generated_augmented_count % 20 == 0: \n",
    "                        logger.info(f\"  - 생성된 증강 이미지 {generated_augmented_count}개 (총 {current_total_images}/{target_total_images}장)\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"증강 파이프라인 오류 ({pipeline_type}, {blend_mode}): {json_file_orig.name} - {e}\")\n",
    "        \n",
    "        logger.info(f\"'{pipeline_type}' ({blend_mode}) 파이프라인 최종 증강 완료: 원본 {original_image_count}장 + 증강 {generated_augmented_count}장 = 총 {current_total_images}장\")\n",
    "        self.visualize_augmentation_results()\n",
    "\n",
    "    def visualize_augmentation_results(self):\n",
    "        set_korean_font() \n",
    "        final_counts_from_output = Counter()\n",
    "        output_label_files = list(self.output_labels_dir.glob('*.json'))\n",
    "        if not output_label_files:\n",
    "            logger.warning(\"출력 디렉토리에 라벨 파일이 없어 시각화를 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        logger.info(f\"시각화를 위해 총 {len(output_label_files)}개의 출력 라벨 파일 분석 중...\")\n",
    "        for json_file in output_label_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    for shape in data['shapes']:\n",
    "                        label = shape.get('label')\n",
    "                        if label and label in self.class_to_idx: \n",
    "                            final_counts_from_output[label] += 1\n",
    "            except Exception as e: logger.warning(f\"출력 라벨 파일 분석 오류: {json_file.name} - {e}\")\n",
    "        logger.info(f\"출력 파일 분석 기반 최종 클래스 분포: {dict(final_counts_from_output)}\")\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(17, 14))\n",
    "        fig.suptitle(\"데이터 증강 결과 분석\", fontsize=20, fontweight='bold', y=0.98)\n",
    "        classes = list(self.class_names)\n",
    "        original_obj_counts = [self.original_class_counts.get(c, 0) for c in classes]\n",
    "        final_obj_counts = [final_counts_from_output.get(c, 0) for c in classes]\n",
    "        x_indices = np.arange(len(classes))\n",
    "        bar_width = 0.35\n",
    "        rects1 = ax1.bar(x_indices - bar_width/2, original_obj_counts, bar_width, label='원본 객체 수', color='deepskyblue', alpha=0.9)\n",
    "        rects2 = ax1.bar(x_indices + bar_width/2, final_obj_counts, bar_width, label='증강 후 객체 수', color='salmon', alpha=0.9)\n",
    "        ax1.set_xlabel('클래스', fontsize=13); ax1.set_ylabel('객체 수', fontsize=13)\n",
    "        ax1.set_title('클래스별 객체 수 비교', fontsize=15); ax1.set_xticks(x_indices)\n",
    "        ax1.set_xticklabels(classes, rotation=45, ha=\"right\", fontsize=10); ax1.legend(fontsize=11)\n",
    "        ax1.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        for rect in rects1 + rects2:\n",
    "            h = rect.get_height()\n",
    "            ax1.text(rect.get_x() + rect.get_width()/2., h, f'{int(h)}', ha='center', va='bottom', fontsize=8)\n",
    "        increase_rates = [((f - o) / o * 100) if o > 0 else (float('inf') if f > 0 else 0) for o, f in zip(original_obj_counts, final_obj_counts)]\n",
    "        colors_bar = ['limegreen' if r >= 100 else 'gold' if r >= 0 else 'tomato' for r in increase_rates]\n",
    "        bars = ax2.bar(classes, increase_rates, color=colors_bar)\n",
    "        ax2.set_xlabel('클래스', fontsize=13); ax2.set_ylabel('객체 수 증가율 (%)', fontsize=13)\n",
    "        ax2.set_title('클래스별 객체 수 증가율', fontsize=15); ax2.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        ax2.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        for bar_idx, bar_item in enumerate(bars):\n",
    "            yval = bar_item.get_height()\n",
    "            ax2.text(bar_item.get_x() + bar_item.get_width()/2., yval, f'{yval:.0f}%' if yval != float('inf') else 'Inf', \n",
    "                     ha='center', va='bottom' if yval >=0 else 'top', fontsize=8)\n",
    "        if sum(final_obj_counts) > 0:\n",
    "            valid_labels = [classes[i] for i, v in enumerate(final_obj_counts) if v > 0]\n",
    "            valid_values = [v for v in final_obj_counts if v > 0]\n",
    "            ax3.pie(valid_values, labels=valid_labels, autopct='%1.1f%%', startangle=120,\n",
    "                    wedgeprops={'edgecolor': 'silver', 'linewidth': 0.7}, textprops={'fontsize': 9})\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15); ax3.axis('equal')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, \"증강된 객체 없음\", ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15)\n",
    "        def gini_coefficient_calc(values):\n",
    "            vals = sorted(filter(lambda x: x > 0, values))\n",
    "            if not vals or len(vals) <= 1: return 0.0\n",
    "            n = len(vals); idx = np.arange(1, n + 1)\n",
    "            return (np.sum((2 * idx - n - 1) * np.array(vals))) / (n * sum(vals)) if sum(vals) > 0 else 0.0\n",
    "        gini_orig = gini_coefficient_calc(original_obj_counts)\n",
    "        gini_final = gini_coefficient_calc(final_obj_counts)\n",
    "        ax4.text(0.5, 0.85, '클래스 균형도 (Gini 계수)', ha='center', va='center', fontsize=15, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.65, f'원본 Gini: {gini_orig:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.55, f'증강 후 Gini: {gini_final:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        improvement_text_val, text_color_val = \"Gini 개선율: N/A\", 'dimgray'\n",
    "        if gini_orig > 1e-6 : \n",
    "            improvement_val = ((gini_orig - gini_final) / gini_orig * 100)\n",
    "            improvement_text_val = f'Gini 개선율: {improvement_val:.1f}%'\n",
    "            text_color_val = 'forestgreen' if improvement_val > 0 else ('tomato' if improvement_val < 0 else 'darkorange')\n",
    "        elif gini_orig <= 1e-6 and gini_final > 1e-6 : improvement_text_val, text_color_val = \"균형 악화됨\", 'tomato'\n",
    "        elif gini_orig <= 1e-6 and gini_final <= 1e-6 : improvement_text_val, text_color_val = \"완벽 균형 유지\", 'forestgreen'\n",
    "        ax4.text(0.5, 0.35, improvement_text_val, ha='center', va='center', fontsize=16, color=text_color_val, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.15, \"(Gini 계수는 0에 가까울수록 균형)\", ha='center', va='center', fontsize=10, style='italic', color='gray', transform=ax4.transAxes)\n",
    "        ax4.axis('off'); plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path_fig = self.output_dir / f'augmentation_summary_{timestamp_str}.png'\n",
    "        try:\n",
    "            plt.savefig(save_path_fig, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"시각화 요약 저장 완료: {save_path_fig}\")\n",
    "        except Exception as e: logger.error(f\"시각화 파일 저장 실패: {e}\")\n",
    "        plt.close(fig)\n",
    "        logger.info(\"\\n=== 최종 통계 요약 (객체 수 기준) ===\")\n",
    "        logger.info(f\"원본 총 객체 수: {sum(original_obj_counts)}개\")\n",
    "        logger.info(f\"증강 후 총 객체 수 (출력 파일 분석): {sum(final_obj_counts)}개\")\n",
    "        for c_name_log in classes:\n",
    "            o_cnt_log, f_cnt_log = self.original_class_counts.get(c_name_log,0), final_counts_from_output.get(c_name_log,0)\n",
    "            inc_str_log = f\"({(f_cnt_log-o_cnt_log)/o_cnt_log*100:.0f}%)\" if o_cnt_log > 0 else \"(원본 0)\"\n",
    "            if f_cnt_log > 0 and o_cnt_log == 0: inc_str_log = \"(신규)\"\n",
    "            logger.info(f\"  - {c_name_log}: {o_cnt_log} → {f_cnt_log} {inc_str_log}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == '__main__':\n",
    "    images_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/images\"\n",
    "    labels_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/labels\"\n",
    "    output_dir_path_base = \"C:/Users/USER/Desktop/증강(cutout+elastic)/augmented_output\"\n",
    "    \n",
    "    augmentor = OptimizedYOLOAugmentation(\n",
    "    images_dir=images_dir_path,\n",
    "    labels_dir=labels_dir_path,\n",
    "    output_dir=output_dir_path_base,\n",
    "    class_names=['ac', 'lc', 'pc', 'tc', 'ph']\n",
    ")\n",
    "    \n",
    "    # 원본 이미지 862장을 기준으로, 약 3배인 2586장을 목표로 설정\n",
    "    target_total_images_for_experiment = 2586 \n",
    "\n",
    "    # --- 실행할 단일 파이프라인 및 블렌드 모드 설정 ---\n",
    "    chosen_pipeline_type = \"elastic_grid_first\"\n",
    "    chosen_blend_mode = \"simple_alpha\" # 기본 블렌딩 모드로 설정\n",
    "\n",
    "    logger.info(f\"\\n\\n{'='*20} 단일 증강 실험 시작 {'='*20}\")\n",
    "    logger.info(f\"파이프라인 유형: {chosen_pipeline_type}\")\n",
    "    logger.info(f\"블렌드 모드: {chosen_blend_mode}\")\n",
    "\n",
    "    # 해당 실험 결과만 저장할 폴더 경로 설정 (단일 실험이므로 output_dir_path_base를 직접 사용)\n",
    "    output_dir_single_exp = Path(output_dir_path_base) \n",
    "    logger.info(f\"출력 폴더: {output_dir_single_exp}\")\n",
    "    \n",
    "    pipeline_single = OptimizedYOLOAugmentation(\n",
    "        images_dir=images_dir_path, labels_dir=labels_dir_path,\n",
    "        output_dir=str(output_dir_single_exp), class_names=class_names\n",
    "    )\n",
    "    pipeline_single.augment_dataset_pipeline(\n",
    "        pipeline_type=chosen_pipeline_type, \n",
    "        target_total_images=target_total_images_for_experiment, \n",
    "        elastic_grid_prob=0.7, \n",
    "        copy_paste_prob=0.8, \n",
    "        num_pastes_range=(1, 3), \n",
    "        blend_mode=chosen_blend_mode \n",
    "    )\n",
    "\n",
    "    logger.info(f\"\\n\\n단일 증강 실험 완료: {chosen_pipeline_type} / {chosen_blend_mode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c682ef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 00:18:40,686 - INFO - \n",
      "\n",
      "==================== 단일 증강 실험 시작 ====================\n",
      "2025-06-07 00:18:40,687 - INFO - 파이프라인 유형: elastic_grid_first\n",
      "2025-06-07 00:18:40,687 - INFO - 블렌드 모드: simple_alpha\n",
      "2025-06-07 00:18:40,688 - INFO - 출력 폴더: C:\\Users\\USER\\Desktop\\증강(cutout+elastic)\\augmented_output\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 924\u001b[0m\n\u001b[0;32m    919\u001b[0m output_dir_single_exp \u001b[38;5;241m=\u001b[39m Path(output_dir_path_base) \n\u001b[0;32m    920\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m출력 폴더: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir_single_exp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    922\u001b[0m pipeline_single \u001b[38;5;241m=\u001b[39m OptimizedYOLOAugmentation(\n\u001b[0;32m    923\u001b[0m     images_dir\u001b[38;5;241m=\u001b[39mimages_dir_path, labels_dir\u001b[38;5;241m=\u001b[39mlabels_dir_path,\n\u001b[1;32m--> 924\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(output_dir_single_exp), class_names\u001b[38;5;241m=\u001b[39mclass_names\n\u001b[0;32m    925\u001b[0m )\n\u001b[0;32m    926\u001b[0m pipeline_single\u001b[38;5;241m.\u001b[39maugment_dataset_pipeline(\n\u001b[0;32m    927\u001b[0m     pipeline_type\u001b[38;5;241m=\u001b[39mchosen_pipeline_type, \n\u001b[0;32m    928\u001b[0m     target_total_images\u001b[38;5;241m=\u001b[39mtarget_total_images_for_experiment, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    932\u001b[0m     blend_mode\u001b[38;5;241m=\u001b[39mchosen_blend_mode \n\u001b[0;32m    933\u001b[0m )\n\u001b[0;32m    935\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m단일 증강 실험 완료: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_pipeline_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchosen_blend_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys \n",
    "import matplotlib.font_manager as fm\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# 로깅 설정 (이전 코드에서 가져옴)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 한글 폰트 설정 함수 (이전 코드에서 가져옴) ---\n",
    "def set_korean_font():\n",
    "    \"\"\"Matplotlib에 한글 폰트를 설정합니다.\"\"\"\n",
    "    try:\n",
    "        if sys.platform == \"win32\":  # Windows\n",
    "            font_name = None\n",
    "            available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "            if 'Malgun Gothic' in available_fonts:\n",
    "                font_name = 'Malgun Gothic'\n",
    "            else: \n",
    "                font_path_win = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "                if os.path.exists(font_path_win):\n",
    "                    try:\n",
    "                        font_prop = fm.FontProperties(fname=font_path_win)\n",
    "                        font_name = font_prop.get_name()\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Windows malgun.ttf 파일에서 폰트 이름 가져오기 실패: {e}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Windows에서 'Malgun Gothic' 폰트를 찾을 수 없습니다. 경로: {font_path_win}\")\n",
    "            \n",
    "            if font_name:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Windows에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            else:\n",
    "                logger.error(\"Windows에서 한글 폰트를 설정하지 못했습니다. 시각화 시 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "        elif sys.platform == \"darwin\":  # macOS\n",
    "            font_name = 'AppleGothic' \n",
    "            try:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"macOS에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            except RuntimeError: \n",
    "                logger.warning(f\"macOS에서 '{font_name}' 폰트를 찾을 수 없습니다. 다른 한글 폰트를 확인해주세요.\")\n",
    "\n",
    "        elif sys.platform.startswith(\"linux\"):  # Linux\n",
    "            font_path_linux = None\n",
    "            nanum_fonts = [f for f in fm.fontManager.ttflist if 'NanumGothic' in f.name]\n",
    "            if nanum_fonts:\n",
    "                font_path_linux = nanum_fonts[0].fname \n",
    "                font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "            else: \n",
    "                font_paths_linux_fallback = [\n",
    "                    \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\",\n",
    "                    \"/usr/share/fonts/nanum/NanumGothic.ttf\",\n",
    "                ]\n",
    "                for path_option in font_paths_linux_fallback:\n",
    "                    if os.path.exists(path_option):\n",
    "                        font_path_linux = path_option\n",
    "                        break\n",
    "                if font_path_linux:\n",
    "                    font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                    plt.rc(\"font\", family=font_name)\n",
    "                    logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "                else:\n",
    "                    logger.error(\"Linux에서 NanumGothic 폰트를 찾을 수 없습니다. 'sudo apt-get install fonts-nanum*'으로 설치해주세요.\")\n",
    "        else:\n",
    "            logger.warning(f\"지원되지 않는 OS 플랫폼({sys.platform})입니다. 한글 폰트가 제대로 설정되지 않을 수 있습니다.\")\n",
    "        plt.rc(\"axes\", unicode_minus=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"한글 폰트 설정 중 오류 발생: {e}\")\n",
    "        logger.warning(\"기본 폰트로 시도합니다. 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "# AdvancedBlending 클래스 (이전 코드에서 가져옴)\n",
    "class AdvancedBlending:\n",
    "    \"\"\"정교한 블렌딩 기법을 적용한 Copy-Paste\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def feather_edges(mask, feather_amount=10):\n",
    "        \"\"\"마스크 가장자리를 부드럽게 페더링\"\"\"\n",
    "        if mask is None or mask.size == 0:\n",
    "            logger.warning(\"페더링할 마스크가 비어있습니다.\")\n",
    "            return mask\n",
    "        if np.all(mask == 0): \n",
    "            return mask.astype(float) \n",
    "            \n",
    "        binary_mask = (mask > 0).astype(np.uint8) \n",
    "        dist_transform = distance_transform_edt(binary_mask)\n",
    "        feather_amount_safe = max(feather_amount, 1e-5)\n",
    "        feathered = np.minimum(dist_transform / feather_amount_safe, 1.0)\n",
    "        return feathered\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_blend(obj_img, background, obj_binary_mask, center_coords):\n",
    "        \"\"\"포아송 블렌딩 (Seamless Cloning)\"\"\"\n",
    "        if obj_img is None or obj_img.size == 0: return background\n",
    "        if background is None or background.size == 0: return background\n",
    "        if obj_binary_mask is None or obj_binary_mask.size == 0: return background\n",
    "\n",
    "        mask_for_poisson = (obj_binary_mask > 0).astype(np.uint8) * 255\n",
    "        \n",
    "        if np.sum(mask_for_poisson) == 0:\n",
    "            logger.warning(\"포아송 블렌딩을 위한 마스크가 비어있습니다. 원본 배경을 반환합니다.\")\n",
    "            return background.copy()\n",
    "\n",
    "        try:\n",
    "            # seamlessClone은 입력 이미지와 마스크의 크기가 같아야 함\n",
    "            if obj_img.shape[:2] != mask_for_poisson.shape[:2]:\n",
    "                logger.warning(f\"Poisson Blend: 객체 이미지({obj_img.shape[:2]})와 마스크({mask_for_poisson.shape[:2]}) 크기가 다릅니다. 마스크를 객체 크기로 조정합니다.\")\n",
    "                mask_for_poisson = cv2.resize(mask_for_poisson, (obj_img.shape[1], obj_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # center_coords가 이미지 경계 내에 있는지 확인 및 조정\n",
    "            h_bg, w_bg = background.shape[:2]\n",
    "            h_obj, w_obj = obj_img.shape[:2]\n",
    "            \n",
    "            if not (0 <= center_coords[0] < w_bg and 0 <= center_coords[1] < h_bg):\n",
    "                logger.error(f\"Poisson Blend: 중심점 {center_coords}이 배경 크기 {background.shape[:2]} 밖에 있습니다.\")\n",
    "                return background.copy()\n",
    "\n",
    "\n",
    "            result = cv2.seamlessClone(\n",
    "                obj_img, \n",
    "                background, \n",
    "                mask_for_poisson, \n",
    "                center_coords, \n",
    "                cv2.NORMAL_CLONE \n",
    "            )\n",
    "            return result\n",
    "        except cv2.error as e:\n",
    "            logger.error(f\"포아송 블렌딩 오류: {e}. 객체 크기: {obj_img.shape}, 마스크 크기: {mask_for_poisson.shape}, 배경 크기: {background.shape}, 중심: {center_coords}\")\n",
    "            return background.copy()\n",
    "\n",
    "    @staticmethod\n",
    "    def multiband_blend(background_roi, obj_img_aligned, obj_mask_aligned_0_1_float_3ch, levels=4):\n",
    "        \"\"\"멀티밴드 블렌딩 (Laplacian Pyramid)\"\"\"\n",
    "        if background_roi is None or obj_img_aligned is None or obj_mask_aligned_0_1_float_3ch is None or \\\n",
    "           background_roi.size == 0 or obj_img_aligned.size == 0 or obj_mask_aligned_0_1_float_3ch.size == 0:\n",
    "            logger.warning(\"멀티밴드 블렌딩 입력값이 유효하지 않습니다.\")\n",
    "            return background_roi \n",
    "        \n",
    "        if background_roi.shape != obj_img_aligned.shape or background_roi.shape != obj_mask_aligned_0_1_float_3ch.shape:\n",
    "            logger.warning(\"멀티밴드 블렌딩: 입력 이미지/마스크 크기가 일치하지 않습니다.\")\n",
    "            return background_roi\n",
    "\n",
    "\n",
    "        gpA = [background_roi.astype(np.float32)] \n",
    "        gpB = [obj_img_aligned.astype(np.float32)] \n",
    "        gpM = [obj_mask_aligned_0_1_float_3ch.astype(np.float32)] \n",
    "\n",
    "        current_levels = 0\n",
    "        for i in range(levels):\n",
    "            if gpA[i].shape[0] < 2 or gpA[i].shape[1] < 2 or \\\n",
    "               gpB[i].shape[0] < 2 or gpB[i].shape[1] < 2 or \\\n",
    "               gpM[i].shape[0] < 2 or gpM[i].shape[1] < 2:\n",
    "                logger.warning(f\"멀티밴드 블렌딩 중 피라미드 레벨 {i+1}에서 이미지 크기가 너무 작아 현재 레벨({i})까지만 처리합니다.\")\n",
    "                levels = i \n",
    "                break\n",
    "            gpA.append(cv2.pyrDown(gpA[i]))\n",
    "            gpB.append(cv2.pyrDown(gpB[i]))\n",
    "            gpM.append(cv2.pyrDown(gpM[i]))\n",
    "            current_levels +=1\n",
    "        \n",
    "        if current_levels == 0 and levels > 0 : \n",
    "             logger.warning(\"멀티밴드 블렌딩: 이미지 크기가 너무 작아 피라미드를 생성할 수 없습니다. 단순 알파 블렌딩으로 대체합니다.\")\n",
    "             blended_roi_content = background_roi * (1 - obj_mask_aligned_0_1_float_3ch) + obj_img_aligned * obj_mask_aligned_0_1_float_3ch\n",
    "             return np.clip(blended_roi_content, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        lpA = [gpA[levels]]\n",
    "        lpB = [gpB[levels]]\n",
    "        for i in range(levels, 0, -1):\n",
    "            size = (gpA[i-1].shape[1], gpA[i-1].shape[0])\n",
    "            lpA.append(cv2.subtract(gpA[i-1], cv2.pyrUp(gpA[i], dstsize=size)))\n",
    "            lpB.append(cv2.subtract(gpB[i-1], cv2.pyrUp(gpB[i], dstsize=size)))\n",
    "        \n",
    "        LS = []\n",
    "        for i in range(levels + 1): \n",
    "            la_current = lpA[i]\n",
    "            lb_current = lpB[i]\n",
    "            gm_current = gpM[levels-i] \n",
    "            \n",
    "            if la_current.shape != gm_current.shape or lb_current.shape != gm_current.shape:\n",
    "                logger.warning(f\"멀티밴드 블렌드 중 레벨 {levels-i}에서 크기 불일치. 마스크 크기 조정 시도.\")\n",
    "                gm_current = cv2.resize(gm_current, (la_current.shape[1], la_current.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "                if gm_current.ndim == 2 and la_current.ndim == 3: \n",
    "                    gm_current = np.stack([gm_current]*3, axis=-1)\n",
    "\n",
    "            ls = la_current * (1.0 - gm_current) + lb_current * gm_current\n",
    "            LS.append(ls)\n",
    "        \n",
    "        ls_ = LS[0] \n",
    "        for i in range(1, levels + 1): \n",
    "            size = (LS[i].shape[1], LS[i].shape[0])\n",
    "            ls_ = cv2.add(cv2.pyrUp(ls_, dstsize=size), LS[i])\n",
    "        \n",
    "        return np.clip(ls_, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def blend_object_onto_background(self, background_orig, obj_img_transformed, obj_mask_transformed_binary, \n",
    "                                     obj_points_transformed_abs, paste_x, paste_y, new_w, new_h,\n",
    "                                     blend_mode='advanced_alpha'):\n",
    "        output_image = background_orig.copy()\n",
    "        y_start, y_end = int(paste_y), int(paste_y + new_h)\n",
    "        x_start, x_end = int(paste_x), int(paste_x + new_w)\n",
    "\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        if y_start < 0 or x_start < 0 or y_end > h_bg or x_end > w_bg:\n",
    "            logger.error(f\"블렌딩 ROI가 이미지 경계를 벗어납니다. ROI: ({x_start},{y_start})-({x_end},{y_end}), BG: ({w_bg},{h_bg})\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        roi_background = output_image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        if obj_img_transformed is None or obj_img_transformed.size == 0 or \\\n",
    "           obj_mask_transformed_binary is None or obj_mask_transformed_binary.size == 0:\n",
    "            logger.warning(\"블렌딩할 객체 이미지 또는 마스크가 비어있습니다.\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        if roi_background.shape[:2] != obj_img_transformed.shape[:2]:\n",
    "            logger.debug(f\"블렌딩 전 ROI({roi_background.shape[:2]})와 객체({obj_img_transformed.shape[:2]}) 크기 불일치. 객체/마스크를 ROI 크기로 조정.\")\n",
    "            obj_img_transformed = cv2.resize(obj_img_transformed, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            obj_mask_transformed_binary = cv2.resize(obj_mask_transformed_binary, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "        harmonized_obj_img = obj_img_transformed.copy()\n",
    "        if blend_mode in ['advanced_alpha', 'color_match_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "            try:\n",
    "                obj_lab = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                roi_lab = cv2.cvtColor(roi_background, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                obj_pixels_lab = obj_lab[obj_mask_transformed_binary > 0]\n",
    "                if obj_pixels_lab.size > 0:\n",
    "                    obj_mean = np.mean(obj_pixels_lab, axis=0); obj_std = np.std(obj_pixels_lab, axis=0)\n",
    "                    roi_mean = np.mean(roi_lab, axis=(0, 1)); roi_std = np.std(roi_lab, axis=(0, 1))\n",
    "                    for i in range(3):\n",
    "                        obj_lab[:, :, i] = np.clip(\n",
    "                            (obj_lab[:, :, i] - obj_mean[i]) * (roi_std[i] / (obj_std[i] + 1e-5)) + roi_mean[i],\n",
    "                            0, 255 \n",
    "                        )\n",
    "                    harmonized_obj_img = cv2.cvtColor(obj_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "                else: logger.debug(\"색상 조화를 위한 객체 픽셀이 없습니다.\")\n",
    "            except cv2.error as e: logger.warning(f\"색상 조화 중 OpenCV 오류: {e}\")\n",
    "\n",
    "            if blend_mode in ['advanced_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "                try:\n",
    "                    roi_gray = cv2.cvtColor(roi_background, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_gray = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_pixels_gray = obj_gray[obj_mask_transformed_binary > 0]\n",
    "                    if obj_pixels_gray.size > 0 and np.mean(obj_pixels_gray) > 1e-5 :\n",
    "                        brightness_ratio = np.mean(roi_gray) / (np.mean(obj_pixels_gray) + 1e-5)\n",
    "                        brightness_ratio = np.clip(brightness_ratio, 0.7, 1.5) \n",
    "                        harmonized_obj_img = cv2.convertScaleAbs(harmonized_obj_img, alpha=brightness_ratio, beta=0)\n",
    "                    else: logger.debug(\"조명 조화를 위한 객체 픽셀이 없거나 평균 밝기가 0에 가깝습니다.\")\n",
    "                except cv2.error as e: logger.warning(f\"조명 조화 중 OpenCV 오류: {e}\")\n",
    "        \n",
    "        if blend_mode == 'poisson' or blend_mode == 'poisson_harmonized':\n",
    "            center_in_bg_abs = (x_start + new_w // 2, y_start + new_h // 2)\n",
    "            output_image = self.poisson_blend(harmonized_obj_img, output_image, obj_mask_transformed_binary, center_in_bg_abs)\n",
    "        \n",
    "        elif blend_mode == 'multiband' or blend_mode == 'multiband_harmonized':\n",
    "            mask_0_1_float_3ch = np.stack([obj_mask_transformed_binary.astype(float)/255.0]*3, axis=-1)\n",
    "            blended_roi_content = self.multiband_blend(roi_background, harmonized_obj_img, mask_0_1_float_3ch)\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content\n",
    "\n",
    "        else: \n",
    "            if blend_mode == 'simple_alpha':\n",
    "                alpha_mask_0_1_float = cv2.GaussianBlur(obj_mask_transformed_binary, (5,5), 0).astype(float) / 255.0\n",
    "            else: \n",
    "                feather_amount = max(3, int(min(new_h, new_w) * 0.03)) \n",
    "                mask_feathered = self.feather_edges(obj_mask_transformed_binary, feather_amount)\n",
    "                blur_ksize = max(3, 2 * int(min(new_h, new_w) * 0.02) + 1) \n",
    "                mask_blur = cv2.GaussianBlur(mask_feathered, (blur_ksize, blur_ksize), 0)\n",
    "                final_alpha_mask_0_1_float = np.clip(mask_blur, 0, 1)\n",
    "                if blend_mode == 'advanced_alpha':\n",
    "                    grad_x = cv2.Sobel(mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "                    grad_y = cv2.Sobel(mask_blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "                    gradient = np.sqrt(grad_x**2 + grad_y**2)\n",
    "                    if np.max(gradient) > 1e-5:\n",
    "                        gradient = gradient / np.max(gradient)\n",
    "                        final_alpha_mask_0_1_float = final_alpha_mask_0_1_float * (1 - gradient * 0.2) \n",
    "                        final_alpha_mask_0_1_float = np.clip(final_alpha_mask_0_1_float, 0, 1)\n",
    "                alpha_mask_0_1_float = final_alpha_mask_0_1_float\n",
    "\n",
    "            alpha_mask_3ch = np.stack([alpha_mask_0_1_float] * 3, axis=-1)\n",
    "            blended_roi_content = roi_background * (1 - alpha_mask_3ch) + harmonized_obj_img * alpha_mask_3ch\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content.astype(np.uint8)\n",
    "\n",
    "            if blend_mode == 'advanced_alpha':\n",
    "                try:\n",
    "                    shadow_kernel_size = max(3, int(min(new_h, new_w) * 0.08)) \n",
    "                    shadow_kernel_size = shadow_kernel_size if shadow_kernel_size % 2 != 0 else shadow_kernel_size + 1 \n",
    "                    dilated_mask = cv2.dilate(obj_mask_transformed_binary, np.ones((shadow_kernel_size//2, shadow_kernel_size//2), np.uint8), iterations=1)\n",
    "                    shadow_alpha_mask = cv2.GaussianBlur(dilated_mask, (shadow_kernel_size, shadow_kernel_size), 0)\n",
    "                    shadow_alpha_mask = shadow_alpha_mask.astype(float) / 255.0 * 0.15 \n",
    "                    shadow_region_float = output_image[y_start:y_end, x_start:x_end].astype(float)\n",
    "                    effective_shadow_alpha = np.clip(shadow_alpha_mask - (obj_mask_transformed_binary.astype(float)/255.0), 0, 1)\n",
    "                    for c in range(3):\n",
    "                        shadow_region_float[:,:,c] *= (1 - effective_shadow_alpha * 0.7) \n",
    "                    output_image[y_start:y_end, x_start:x_end] = np.clip(shadow_region_float, 0, 255).astype(np.uint8)\n",
    "                except Exception as e: logger.warning(f\"그림자 효과 적용 중 오류: {e}\")\n",
    "        return output_image, obj_points_transformed_abs\n",
    "\n",
    "\n",
    "class OptimizedYOLOAugmentation:\n",
    "    def __init__(self, images_dir, labels_dir, output_dir, class_names=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_images_dir = self.output_dir / 'images'\n",
    "        self.output_labels_dir = self.output_dir / 'labels'\n",
    "        self.output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.class_names = class_names or ['ac', 'lc', 'pc', 'tc', 'ph']\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "        self.class_objects = defaultdict(list)\n",
    "        self.original_class_counts = Counter()\n",
    "        self.augmented_class_counts = Counter() \n",
    "        self.min_object_size = 30\n",
    "        self.max_object_ratio = 0.4\n",
    "        self.blender = AdvancedBlending()\n",
    "\n",
    "    def analyze_dataset(self):\n",
    "        logger.info(\"데이터셋 분석 중...\")\n",
    "        self.original_class_counts.clear()\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다.\")\n",
    "            return self.original_class_counts\n",
    "        total_images_processed = 0\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    total_images_processed +=1\n",
    "                    for shape in data['shapes']:\n",
    "                        if 'label' in shape and shape['label'] in self.class_to_idx:\n",
    "                            self.original_class_counts[shape['label']] += 1\n",
    "                        elif 'label' in shape:\n",
    "                            logger.warning(f\"라벨 파일 '{json_file.name}'에 정의되지 않은 클래스 '{shape['label']}'가 있습니다.\")\n",
    "            except json.JSONDecodeError: logger.error(f\"JSON 파싱 오류: {json_file}\")\n",
    "            except Exception as e: logger.error(f\"파일 분석 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {total_images_processed}개의 이미지 라벨 분석 완료.\")\n",
    "        logger.info(f\"원본 클래스별 분포: {dict(self.original_class_counts)}\")\n",
    "        return self.original_class_counts\n",
    "    \n",
    "    def calculate_optimized_weights(self):\n",
    "        if not self.original_class_counts:\n",
    "            logger.warning(\"원본 클래스 카운트가 없어 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        total_objects = sum(self.original_class_counts.values())\n",
    "        num_classes_with_objects = len([c_name for c_name, count in self.original_class_counts.items() if count > 0])\n",
    "\n",
    "        if total_objects == 0 or num_classes_with_objects == 0:\n",
    "            logger.warning(\"객체가 없거나 객체가 있는 클래스가 없어 유효한 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        \n",
    "        weights = {}\n",
    "        for class_name in self.class_names: \n",
    "            count = self.original_class_counts.get(class_name, 0)\n",
    "            if count > 0: \n",
    "                weight = np.sqrt(total_objects / (num_classes_with_objects * count))\n",
    "            else: \n",
    "                weight = 0 \n",
    "            weights[class_name] = weight\n",
    "        \n",
    "        valid_weights = [w for w in weights.values() if w > 0]\n",
    "        max_calculated_weight = max(valid_weights) if valid_weights else 1.0 \n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            if weights[class_name] == 0: \n",
    "                weights[class_name] = max_calculated_weight * 1.5 \n",
    "        \n",
    "        logger.info(f\"최적화된 증강 가중치: {weights}\")\n",
    "        return weights\n",
    "\n",
    "    def intelligent_copy_paste_with_advanced_blending(self, background_orig, \n",
    "                                                      class_weights, \n",
    "                                                      num_pastes_range=(1, 4), \n",
    "                                                      difficulty_level='medium',\n",
    "                                                      blend_mode='advanced_alpha'):\n",
    "        if not any(self.class_objects.values()):\n",
    "            logger.warning(\"Copy-Paste를 위한 추출된 객체가 없습니다.\")\n",
    "            return background_orig, [] \n",
    "\n",
    "        output_image = background_orig.copy()\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        pasted_shapes_info = [] \n",
    "\n",
    "        min_pastes, max_pastes = num_pastes_range\n",
    "        if difficulty_level == 'easy':\n",
    "            num_pastes_actual = random.randint(min_pastes, max(min_pastes, (min_pastes + max_pastes) // 3))\n",
    "        elif difficulty_level == 'medium':\n",
    "            num_pastes_actual = random.randint(min_pastes, max_pastes)\n",
    "        else: \n",
    "            num_pastes_actual = random.randint(max_pastes, int(max_pastes * 1.5))\n",
    "            num_pastes_actual = min(num_pastes_actual, 8) \n",
    "        \n",
    "        if not class_weights or not any(v > 0 for v in class_weights.values()):\n",
    "            logger.warning(\"유효한 클래스 가중치가 없어 Copy-Paste를 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return output_image, []\n",
    "\n",
    "        classes_with_objects_and_weights = [cn for cn in class_weights if class_weights.get(cn, 0) > 0 and self.class_objects.get(cn)]\n",
    "        if not classes_with_objects_and_weights:\n",
    "            logger.warning(\"붙여넣을 수 있는 객체가 있는 클래스가 없거나 가중치가 없습니다.\")\n",
    "            return output_image, []\n",
    "        weights_for_choice = [class_weights[cn] for cn in classes_with_objects_and_weights]\n",
    "\n",
    "        occupied_bboxes = [] \n",
    "        successfully_pasted_count = 0\n",
    "\n",
    "        for _ in range(num_pastes_actual):\n",
    "            try:\n",
    "                selected_class = random.choices(classes_with_objects_and_weights, weights=weights_for_choice)[0]\n",
    "            except IndexError:\n",
    "                logger.warning(\"가중치 기반 클래스 선택 실패. 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "                continue\n",
    "            \n",
    "            if not self.class_objects[selected_class]: continue\n",
    "\n",
    "            obj_data = random.choice(self.class_objects[selected_class])\n",
    "            obj_img_to_paste = obj_data['image'] \n",
    "            obj_mask_to_paste = obj_data['mask'] \n",
    "            obj_points_relative = obj_data['points'].copy() \n",
    "\n",
    "            if obj_img_to_paste is None or obj_img_to_paste.size == 0 or \\\n",
    "               obj_mask_to_paste is None or obj_mask_to_paste.size == 0:\n",
    "                logger.warning(f\"선택된 객체 '{selected_class}'의 이미지 또는 마스크가 비어있습니다.\")\n",
    "                continue\n",
    "\n",
    "            h_obj_orig, w_obj_orig = obj_img_to_paste.shape[:2]\n",
    "\n",
    "            current_scale = random.uniform(0.6, 1.4)\n",
    "            current_rotation = 0\n",
    "            if random.random() < 0.4: current_rotation = random.uniform(-20, 20)\n",
    "            \n",
    "            transform_center = (w_obj_orig // 2, h_obj_orig // 2)\n",
    "            M_transform = cv2.getRotationMatrix2D(transform_center, current_rotation, current_scale)\n",
    "            \n",
    "            cos_t = np.abs(M_transform[0, 0]); sin_t = np.abs(M_transform[0, 1])\n",
    "            new_obj_w = int((h_obj_orig * sin_t) + (w_obj_orig * cos_t))\n",
    "            new_obj_h = int((h_obj_orig * cos_t) + (w_obj_orig * sin_t))\n",
    "\n",
    "            if new_obj_w == 0 or new_obj_h == 0: continue\n",
    "\n",
    "            M_transform[0, 2] += (new_obj_w / 2) - transform_center[0]\n",
    "            M_transform[1, 2] += (new_obj_h / 2) - transform_center[1]\n",
    "            \n",
    "            final_obj_img = cv2.warpAffine(obj_img_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "            final_obj_mask_binary = cv2.warpAffine(obj_mask_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=(0))\n",
    "            \n",
    "            ones_homo = np.ones((obj_points_relative.shape[0], 1))\n",
    "            points_homo = np.hstack([obj_points_relative, ones_homo])\n",
    "            final_obj_points_relative_transformed = (M_transform @ points_homo.T).T \n",
    "\n",
    "            if new_obj_h >= h_bg or new_obj_w >= w_bg: continue\n",
    "            \n",
    "            if random.random() < 0.3: \n",
    "                color_aug = A.Compose([\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=1.0),\n",
    "                    A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=18, val_shift_limit=12, p=1.0)\n",
    "                ])\n",
    "                final_obj_img = color_aug(image=final_obj_img)['image']\n",
    "\n",
    "            paste_margin = max(5, int(0.01 * min(h_bg, w_bg)))\n",
    "            if w_bg - new_obj_w - 2 * paste_margin <= 0 or h_bg - new_obj_h - 2 * paste_margin <= 0: continue\n",
    "            \n",
    "            found_position = False\n",
    "            for _ in range(30): \n",
    "                current_paste_x = random.randint(paste_margin, w_bg - new_obj_w - paste_margin)\n",
    "                current_paste_y = random.randint(paste_margin, h_bg - new_obj_h - paste_margin)\n",
    "                current_bbox_abs = [current_paste_x, current_paste_y, current_paste_x + new_obj_w, current_paste_y + new_obj_h]\n",
    "                \n",
    "                if any(self.calculate_iou(current_bbox_abs, occ_bbox) > 0.15 for occ_bbox in occupied_bboxes):\n",
    "                    continue\n",
    "                \n",
    "                output_image, _ = self.blender.blend_object_onto_background(\n",
    "                    output_image, final_obj_img, final_obj_mask_binary, \n",
    "                    None, \n",
    "                    current_paste_x, current_paste_y, new_obj_w, new_obj_h,\n",
    "                    blend_mode=blend_mode\n",
    "                )\n",
    "                \n",
    "                abs_points_for_label = (final_obj_points_relative_transformed + np.array([current_paste_x, current_paste_y])).astype(np.int32).tolist()\n",
    "                pasted_shapes_info.append({\n",
    "                    'label': selected_class,\n",
    "                    'points': abs_points_for_label, \n",
    "                    'group_id': None, 'shape_type': 'polygon', 'flags': {}\n",
    "                })\n",
    "                occupied_bboxes.append(current_bbox_abs)\n",
    "                successfully_pasted_count += 1\n",
    "                found_position = True\n",
    "                break\n",
    "        \n",
    "        logger.debug(f\"{successfully_pasted_count}개의 객체(Advanced Blending) 붙여넣기 완료 (시도: {num_pastes_actual}개).\")\n",
    "        return output_image, pasted_shapes_info\n",
    "    \n",
    "    def apply_geometric_transform(self, image, shapes, transform_prob=0.8):\n",
    "        \"\"\"\n",
    "        이미지, 마스크 및 모든 shape의 폴리곤 좌표에 기하 변형(Cutout, Elastic, Grid)을 적용합니다.\n",
    "        shapes: [{'label': 'name', 'points': [[x1,y1], ...], ...}, ...]\n",
    "        \"\"\"\n",
    "        if random.random() >= transform_prob: \n",
    "            return image, shapes\n",
    "\n",
    "        # Cutout은 keypoints를 지원하지 않으므로, 이미지에만 별도로 적용합니다.\n",
    "        # Cutout을 먼저 적용\n",
    "        cutout_transform = A.Compose([\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.7) # p=확률, num_holes=자르는 사각형 개수, max_h/w_size=최대 크기, fill_value=채울 색상\n",
    "        ])\n",
    "        \n",
    "        # Cutout을 먼저 적용\n",
    "        transformed_image = cutout_transform(image=image)['image']\n",
    "\n",
    "        # 이후 ElasticTransform과 GridDistortion 적용 (keypoints 포함)\n",
    "        geometric_transform_pipeline = A.Compose([\n",
    "            A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7, \n",
    "                               border_mode=cv2.BORDER_REFLECT_101),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7, \n",
    "                             border_mode=cv2.BORDER_REFLECT_101),\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['shape_indices'], remove_invisible=False))\n",
    "\n",
    "        all_keypoints_flat = []\n",
    "        keypoint_shape_indices = [] \n",
    "        points_per_shape_count = [] \n",
    "\n",
    "        for idx, shape_dict in enumerate(shapes):\n",
    "            points = shape_dict.get('points', [])\n",
    "            if points and len(points) >=3 : \n",
    "                all_keypoints_flat.extend(points) \n",
    "                keypoint_shape_indices.extend([idx] * len(points)) \n",
    "                points_per_shape_count.append(len(points))\n",
    "            else:\n",
    "                points_per_shape_count.append(0) \n",
    "\n",
    "        if not all_keypoints_flat: \n",
    "            # 키포인트가 없으면 기하 변형은 이미지에만 적용\n",
    "            img_only_geometric_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7,\n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7,\n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_geometric_pipeline(image=transformed_image)['image'] # 이미 Cutout 적용된 이미지에 적용\n",
    "            return transformed_image, shapes \n",
    "\n",
    "        try:\n",
    "            # Cutout이 적용된 이미지와 함께 keypoints에 기하 변형 적용\n",
    "            transformed_data = geometric_transform_pipeline(image=transformed_image, keypoints=all_keypoints_flat, shape_indices=keypoint_shape_indices)\n",
    "            transformed_image = transformed_data['image']\n",
    "            transformed_keypoints_flat = transformed_data['keypoints']\n",
    "\n",
    "            new_shapes = []\n",
    "            current_kp_idx = 0\n",
    "            for shape_idx, original_shape_dict in enumerate(shapes):\n",
    "                num_points_for_this_shape = points_per_shape_count[shape_idx]\n",
    "                new_shape = original_shape_dict.copy()\n",
    "                if num_points_for_this_shape > 0:\n",
    "                    shape_keypoints = transformed_keypoints_flat[current_kp_idx : current_kp_idx + num_points_for_this_shape]\n",
    "                    new_shape['points'] = np.array(shape_keypoints, dtype=np.int32).tolist()\n",
    "                    current_kp_idx += num_points_for_this_shape\n",
    "                else: \n",
    "                    new_shape['points'] = [] \n",
    "                new_shapes.append(new_shape)\n",
    "            \n",
    "            return transformed_image, new_shapes\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"기하 변형 중 오류 발생: {e}. 이미지 변형만 시도합니다.\")\n",
    "            img_only_geometric_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=1.0, \n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=1.0, \n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_geometric_pipeline(image=transformed_image)['image'] # 이미 Cutout 적용된 이미지에 적용\n",
    "            return transformed_image, shapes \n",
    "\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        x1_inter = max(box1[0], box2[0])\n",
    "        y1_inter = max(box1[1], box2[1])\n",
    "        x2_inter = min(box1[2], box2[2])\n",
    "        y2_inter = min(box1[3], box2[3])\n",
    "        intersection_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "        if intersection_area == 0: return 0.0\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union_area = area1 + area2 - intersection_area\n",
    "        return intersection_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "    def extract_objects_from_dataset(self):\n",
    "        logger.info(\"고품질 객체 추출 중...\")\n",
    "        self.class_objects.clear()\n",
    "        extracted_count = 0\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다. 객체 추출을 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        for idx, json_file in enumerate(json_files):\n",
    "            if idx % 50 == 0: logger.info(f\"객체 추출 진행: {idx}/{len(json_files)}\")\n",
    "            try:\n",
    "                base_name = json_file.stem\n",
    "                img_file, _ = self._find_image_file(base_name)\n",
    "                if not img_file:\n",
    "                    logger.warning(f\"객체 추출을 위한 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "                image = cv2.imread(str(img_file))\n",
    "                if image is None:\n",
    "                    logger.warning(f\"이미지 로드 실패: {img_file}\")\n",
    "                    continue\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' not in data: continue\n",
    "                for shape in data['shapes']:\n",
    "                    if shape.get('shape_type') != 'polygon' or 'label' not in shape: continue\n",
    "                    label = shape['label']\n",
    "                    if label not in self.class_to_idx:\n",
    "                        logger.debug(f\"객체 추출 중 정의되지 않은 라벨 '{label}' 발견: {json_file.name}\")\n",
    "                        continue\n",
    "                    points_list = shape.get('points', [])\n",
    "                    if not points_list or len(points_list) < 3: continue\n",
    "                    points = np.array(points_list, dtype=np.int32)\n",
    "                    x, y, w, h = cv2.boundingRect(points)\n",
    "                    if not (self.min_object_size <= w < image.shape[1] * self.max_object_ratio and \\\n",
    "                            self.min_object_size <= h < image.shape[0] * self.max_object_ratio):\n",
    "                        continue\n",
    "                    if h == 0: continue\n",
    "                    aspect_ratio = w / h\n",
    "                    if not (0.2 < aspect_ratio < 5.0): continue\n",
    "                    obj_region_mask_full = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "                    cv2.fillPoly(obj_region_mask_full, [points], 255)\n",
    "                    obj_img_cropped = image[y:y+h, x:x+w].copy()\n",
    "                    obj_mask_cropped = obj_region_mask_full[y:y+h, x:x+w].copy() \n",
    "                    obj_img_masked = cv2.bitwise_and(obj_img_cropped, obj_img_cropped, mask=obj_mask_cropped)\n",
    "                    relative_points = points - np.array([x, y])\n",
    "                    self.class_objects[label].append({\n",
    "                        'image': obj_img_masked,    \n",
    "                        'mask': obj_mask_cropped,  \n",
    "                        'points': relative_points,  \n",
    "                    })\n",
    "                    extracted_count += 1\n",
    "            except Exception as e: logger.exception(f\"객체 추출 중 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {extracted_count}개의 객체 추출 완료.\")\n",
    "        for class_name, objects in self.class_objects.items():\n",
    "            logger.info(f\"  - {class_name}: {len(objects)}개\")\n",
    "\n",
    "    def _find_image_file(self, base_name):\n",
    "        possible_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', \n",
    "                               '.JPG', '.JPEG', '.PNG', '.BMP', '.TIFF']\n",
    "        for ext in possible_extensions:\n",
    "            potential_file = self.images_dir / f\"{base_name}{ext}\"\n",
    "            if potential_file.exists():\n",
    "                return potential_file, ext\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "    def augment_dataset_pipeline(self, pipeline_type=\"copy_paste_first\", \n",
    "                                target_total_images=2400, \n",
    "                                elastic_grid_prob=0.8,\n",
    "                                copy_paste_prob=0.9, \n",
    "                                num_pastes_range=(1,3),\n",
    "                                blend_mode='advanced_alpha'):\n",
    "        logger.info(f\"'{pipeline_type}' (블렌드: {blend_mode}) 파이프라인으로 데이터셋 증강 시작: 목표 {target_total_images}장\")\n",
    "\n",
    "        self.analyze_dataset()\n",
    "        if not self.original_class_counts:\n",
    "            logger.error(\"원본 데이터셋 분석 실패. 증강 중단.\")\n",
    "            return\n",
    "\n",
    "        class_weights = self.calculate_optimized_weights()\n",
    "        if not class_weights:\n",
    "            logger.error(\"클래스 가중치 계산 실패. 증강 중단.\")\n",
    "            return\n",
    "        \n",
    "        self.extract_objects_from_dataset()\n",
    "\n",
    "        logger.info(\"원본 파일 복사 중...\")\n",
    "        json_files_original = list(self.labels_dir.glob('*.json'))\n",
    "        original_image_count = len(json_files_original)\n",
    "\n",
    "        for json_file_idx, json_file in enumerate(json_files_original):\n",
    "            if json_file_idx % 100 == 0:\n",
    "                 logger.info(f\"원본 파일 복사 진행: {json_file_idx}/{len(json_files_original)}\")\n",
    "            base_name = json_file.stem\n",
    "            img_file, img_ext_found = self._find_image_file(base_name)\n",
    "            if img_file:\n",
    "                try:\n",
    "                    shutil.copy2(img_file, self.output_images_dir / img_file.name)\n",
    "                    shutil.copy2(json_file, self.output_labels_dir / json_file.name)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"원본 파일 복사 실패: {img_file} 또는 {json_file} - {e}\")\n",
    "            else:\n",
    "                logger.warning(f\"원본 이미지 파일을 찾지 못해 복사하지 못했습니다: {self.images_dir / base_name}\")\n",
    "\n",
    "        current_total_images = original_image_count\n",
    "        generated_augmented_count = 0\n",
    "        \n",
    "        difficulty_levels = ['easy', 'medium', 'hard']\n",
    "        difficulty_probs = [0.3, 0.5, 0.2]\n",
    "\n",
    "        while current_total_images < target_total_images:\n",
    "            random.shuffle(json_files_original)\n",
    "            for json_file_orig in json_files_original:\n",
    "                if current_total_images >= target_total_images: break\n",
    "\n",
    "                base_name = json_file_orig.stem\n",
    "                img_file_orig, img_ext = self._find_image_file(base_name)\n",
    "\n",
    "                if not img_file_orig:\n",
    "                    logger.warning(f\"증강을 위한 원본 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    image = cv2.imread(str(img_file_orig))\n",
    "                    if image is None:\n",
    "                        logger.warning(f\"이미지 로드 실패: {img_file_orig}\")\n",
    "                        continue\n",
    "                    \n",
    "                    with open(json_file_orig, 'r', encoding='utf-8') as f:\n",
    "                        label_data = json.load(f)\n",
    "                    \n",
    "                    original_shapes = label_data.get('shapes', []) \n",
    "                    augmented_image = image.copy()\n",
    "                    current_shapes = [s.copy() for s in original_shapes] \n",
    "\n",
    "                    difficulty = random.choices(difficulty_levels, difficulty_probs)[0]\n",
    "\n",
    "                    if pipeline_type == \"copy_paste_first\": \n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights,\n",
    "                                num_pastes_range=num_pastes_range,\n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"CPF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                        \n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"CPF: Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "\n",
    "                    elif pipeline_type == \"elastic_grid_first\": \n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"EGF: Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights, \n",
    "                                num_pastes_range=num_pastes_range, \n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"EGF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                            \n",
    "                    else:\n",
    "                        logger.error(f\"알 수 없는 파이프라인 유형: {pipeline_type}\")\n",
    "                        continue\n",
    "                    \n",
    "                    current_shapes = [s for s in current_shapes if s.get('points') and len(s['points']) >= 3]\n",
    "\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "                    aug_base_name = f\"{base_name}_{pipeline_type}_{blend_mode}_{timestamp}_{random.randint(1000,9999)}\"\n",
    "                    aug_img_path = self.output_images_dir / f\"{aug_base_name}{img_ext}\" \n",
    "                    aug_label_path = self.output_labels_dir / f\"{aug_base_name}.json\"\n",
    "\n",
    "                    cv2.imwrite(str(aug_img_path), augmented_image)\n",
    "                    \n",
    "                    final_label_data = {\n",
    "                        \"version\": label_data.get(\"version\", \"5.0.0\"), \"flags\": label_data.get(\"flags\", {}),\n",
    "                        \"shapes\": current_shapes, \n",
    "                        \"imagePath\": aug_img_path.name, \"imageData\": None,\n",
    "                        \"imageHeight\": augmented_image.shape[0], \"imageWidth\": augmented_image.shape[1]\n",
    "                    }\n",
    "                    with open(aug_label_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(final_label_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    generated_augmented_count += 1\n",
    "                    current_total_images += 1\n",
    "                    if generated_augmented_count % 20 == 0: \n",
    "                        logger.info(f\"  - 생성된 증강 이미지 {generated_augmented_count}개 (총 {current_total_images}/{target_total_images}장)\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"증강 파이프라인 오류 ({pipeline_type}, {blend_mode}): {json_file_orig.name} - {e}\")\n",
    "        \n",
    "        logger.info(f\"'{pipeline_type}' ({blend_mode}) 파이프라인 최종 증강 완료: 원본 {original_image_count}장 + 증강 {generated_augmented_count}장 = 총 {current_total_images}장\")\n",
    "        self.visualize_augmentation_results()\n",
    "\n",
    "    def visualize_augmentation_results(self):\n",
    "        set_korean_font() \n",
    "        final_counts_from_output = Counter()\n",
    "        output_label_files = list(self.output_labels_dir.glob('*.json'))\n",
    "        if not output_label_files:\n",
    "            logger.warning(\"출력 디렉토리에 라벨 파일이 없어 시각화를 건너<0xEB><0><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        logger.info(f\"시각화를 위해 총 {len(output_label_files)}개의 출력 라벨 파일 분석 중...\")\n",
    "        for json_file in output_label_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    for shape in data['shapes']:\n",
    "                        label = shape.get('label')\n",
    "                        if label and label in self.class_to_idx: \n",
    "                            final_counts_from_output[label] += 1\n",
    "            except Exception as e: logger.warning(f\"출력 라벨 파일 분석 오류: {json_file.name} - {e}\")\n",
    "        logger.info(f\"출력 파일 분석 기반 최종 클래스 분포: {dict(final_counts_from_output)}\")\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(17, 14))\n",
    "        fig.suptitle(\"데이터 증강 결과 분석\", fontsize=20, fontweight='bold', y=0.98)\n",
    "        classes = list(self.class_names)\n",
    "        original_obj_counts = [self.original_class_counts.get(c, 0) for c in classes]\n",
    "        final_obj_counts = [final_counts_from_output.get(c, 0) for c in classes]\n",
    "        x_indices = np.arange(len(classes))\n",
    "        bar_width = 0.35\n",
    "        rects1 = ax1.bar(x_indices - bar_width/2, original_obj_counts, bar_width, label='원본 객체 수', color='deepskyblue', alpha=0.9)\n",
    "        rects2 = ax1.bar(x_indices + bar_width/2, final_obj_counts, bar_width, label='증강 후 객체 수', color='salmon', alpha=0.9)\n",
    "        ax1.set_xlabel('클래스', fontsize=13); ax1.set_ylabel('객체 수', fontsize=13)\n",
    "        ax1.set_title('클래스별 객체 수 비교', fontsize=15); ax1.set_xticks(x_indices)\n",
    "        ax1.set_xticklabels(classes, rotation=45, ha=\"right\", fontsize=10); ax1.legend(fontsize=11)\n",
    "        ax1.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        for rect in rects1 + rects2:\n",
    "            h = rect.get_height()\n",
    "            ax1.text(rect.get_x() + rect.get_width()/2., h, f'{int(h)}', ha='center', va='bottom', fontsize=8)\n",
    "        increase_rates = [((f - o) / o * 100) if o > 0 else (float('inf') if f > 0 else 0) for o, f in zip(original_obj_counts, final_obj_counts)]\n",
    "        colors_bar = ['limegreen' if r >= 100 else 'gold' if r >= 0 else 'tomato' for r in increase_rates]\n",
    "        bars = ax2.bar(classes, increase_rates, color=colors_bar)\n",
    "        ax2.set_xlabel('클래스', fontsize=13); ax2.set_ylabel('객체 수 증가율 (%)', fontsize=13)\n",
    "        ax2.set_title('클래스별 객체 수 증가율', fontsize=15); ax2.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        ax2.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        for bar_idx, bar_item in enumerate(bars):\n",
    "            yval = bar_item.get_height()\n",
    "            ax2.text(bar_item.get_x() + bar_item.get_width()/2., yval, f'{yval:.0f}%' if yval != float('inf') else 'Inf', \n",
    "                     ha='center', va='bottom' if yval >=0 else 'top', fontsize=8)\n",
    "        if sum(final_obj_counts) > 0:\n",
    "            valid_labels = [classes[i] for i, v in enumerate(final_obj_counts) if v > 0]\n",
    "            valid_values = [v for v in final_obj_counts if v > 0]\n",
    "            ax3.pie(valid_values, labels=valid_labels, autopct='%1.1f%%', startangle=120,\n",
    "                    wedgeprops={'edgecolor': 'silver', 'linewidth': 0.7}, textprops={'fontsize': 9})\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15); ax3.axis('equal')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, \"증강된 객체 없음\", ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15)\n",
    "        def gini_coefficient_calc(values):\n",
    "            vals = sorted(filter(lambda x: x > 0, values))\n",
    "            if not vals or len(vals) <= 1: return 0.0\n",
    "            n = len(vals); idx = np.arange(1, n + 1)\n",
    "            return (np.sum((2 * idx - n - 1) * np.array(vals))) / (n * sum(vals)) if sum(vals) > 0 else 0.0\n",
    "        gini_orig = gini_coefficient_calc(original_obj_counts)\n",
    "        gini_final = gini_coefficient_calc(final_obj_counts)\n",
    "        ax4.text(0.5, 0.85, '클래스 균형도 (Gini 계수)', ha='center', va='center', fontsize=15, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.65, f'원본 Gini: {gini_orig:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.55, f'증강 후 Gini: {gini_final:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        improvement_text_val, text_color_val = \"Gini 개선율: N/A\", 'dimgray'\n",
    "        if gini_orig > 1e-6 : \n",
    "            improvement_val = ((gini_orig - gini_final) / gini_orig * 100)\n",
    "            improvement_text_val = f'Gini 개선율: {improvement_val:.1f}%'\n",
    "            text_color_val = 'forestgreen' if improvement_val > 0 else ('tomato' if improvement_val < 0 else 'darkorange')\n",
    "        elif gini_orig <= 1e-6 and gini_final > 1e-6 : improvement_text_val, text_color_val = \"균형 악화됨\", 'tomato'\n",
    "        elif gini_orig <= 1e-6 and gini_final <= 1e-6 : improvement_text_val, text_color_val = \"완벽 균형 유지\", 'forestgreen'\n",
    "        ax4.text(0.5, 0.35, improvement_text_val, ha='center', va='center', fontsize=16, color=text_color_val, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.15, \"(Gini 계수는 0에 가까울수록 균형)\", ha='center', va='center', fontsize=10, style='italic', color='gray', transform=ax4.transAxes)\n",
    "        ax4.axis('off'); plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path_fig = self.output_dir / f'augmentation_summary_{timestamp_str}.png'\n",
    "        try:\n",
    "            plt.savefig(save_path_fig, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"시각화 요약 저장 완료: {save_path_fig}\")\n",
    "        except Exception as e: logger.error(f\"시각화 파일 저장 실패: {e}\")\n",
    "        plt.close(fig)\n",
    "        logger.info(\"\\n=== 최종 통계 요약 (객체 수 기준) ===\")\n",
    "        logger.info(f\"원본 총 객체 수: {sum(original_obj_counts)}개\")\n",
    "        logger.info(f\"증강 후 총 객체 수 (출력 파일 분석): {sum(final_obj_counts)}개\")\n",
    "        for c_name_log in classes:\n",
    "            o_cnt_log, f_cnt_log = self.original_class_counts.get(c_name_log,0), final_counts_from_output.get(c_name_log,0)\n",
    "            inc_str_log = f\"({(f_cnt_log-o_cnt_log)/o_cnt_log*100:.0f}%)\" if o_cnt_log > 0 else \"(원본 0)\"\n",
    "            if f_cnt_log > 0 and o_cnt_log == 0: inc_str_log = \"(신규)\"\n",
    "            logger.info(f\"  - {c_name_log}: {o_cnt_log} → {f_cnt_log} {inc_str_log}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == '__main__':\n",
    "    images_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/images\"\n",
    "    labels_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/labels\"\n",
    "    output_dir_path_base = \"C:/Users/USER/Desktop/증강(cutout+elastic)/augmented_output\"\n",
    "    \n",
    "    augmentor = OptimizedYOLOAugmentation(\n",
    "    images_dir=images_dir_path,\n",
    "    labels_dir=labels_dir_path,\n",
    "    output_dir=output_dir_path_base,\n",
    "    class_names=['ac', 'lc', 'pc', 'tc', 'ph']\n",
    ")\n",
    "    \n",
    "    # 원본 이미지 862장을 기준으로, 약 3배인 2586장을 목표로 설정\n",
    "    target_total_images_for_experiment = 2586 \n",
    "\n",
    "    # --- 실행할 단일 파이프라인 및 블렌드 모드 설정 ---\n",
    "    chosen_pipeline_type = \"elastic_grid_first\"\n",
    "    chosen_blend_mode = \"simple_alpha\" # 기본 블렌딩 모드로 설정\n",
    "\n",
    "    logger.info(f\"\\n\\n{'='*20} 단일 증강 실험 시작 {'='*20}\")\n",
    "    logger.info(f\"파이프라인 유형: {chosen_pipeline_type}\")\n",
    "    logger.info(f\"블렌드 모드: {chosen_blend_mode}\")\n",
    "\n",
    "    # 해당 실험 결과만 저장할 폴더 경로 설정 (단일 실험이므로 output_dir_path_base를 직접 사용)\n",
    "    output_dir_single_exp = Path(output_dir_path_base) \n",
    "    logger.info(f\"출력 폴더: {output_dir_single_exp}\")\n",
    "    \n",
    "    pipeline_single = OptimizedYOLOAugmentation(\n",
    "        images_dir=images_dir_path, labels_dir=labels_dir_path,\n",
    "        output_dir=str(output_dir_single_exp), class_names=class_names\n",
    "    )\n",
    "    pipeline_single.augment_dataset_pipeline(\n",
    "        pipeline_type=chosen_pipeline_type, \n",
    "        target_total_images=target_total_images_for_experiment, \n",
    "        elastic_grid_prob=0.7, \n",
    "        copy_paste_prob=0.8, \n",
    "        num_pastes_range=(1, 3), \n",
    "        blend_mode=chosen_blend_mode \n",
    "    )\n",
    "\n",
    "    logger.info(f\"\\n\\n단일 증강 실험 완료: {chosen_pipeline_type} / {chosen_blend_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa835b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys \n",
    "import matplotlib.font_manager as fm\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# 로깅 설정 (이전 코드에서 가져옴)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- 한글 폰트 설정 함수 (이전 코드에서 가져옴) ---\n",
    "def set_korean_font():\n",
    "    \"\"\"Matplotlib에 한글 폰트를 설정합니다.\"\"\"\n",
    "    try:\n",
    "        if sys.platform == \"win32\":  # Windows\n",
    "            font_name = None\n",
    "            available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
    "            if 'Malgun Gothic' in available_fonts:\n",
    "                font_name = 'Malgun Gothic'\n",
    "            else: \n",
    "                font_path_win = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "                if os.path.exists(font_path_win):\n",
    "                    try:\n",
    "                        font_prop = fm.FontProperties(fname=font_path_win)\n",
    "                        font_name = font_prop.get_name()\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Windows malgun.ttf 파일에서 폰트 이름 가져오기 실패: {e}\")\n",
    "                else:\n",
    "                    logger.warning(f\"Windows에서 'Malgun Gothic' 폰트를 찾을 수 없습니다. 경로: {font_path_win}\")\n",
    "            \n",
    "            if font_name:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Windows에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            else:\n",
    "                logger.error(\"Windows에서 한글 폰트를 설정하지 못했습니다. 시각화 시 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "        elif sys.platform == \"darwin\":  # macOS\n",
    "            font_name = 'AppleGothic' \n",
    "            try:\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"macOS에서 '{font_name}' 폰트를 설정했습니다.\")\n",
    "            except RuntimeError: \n",
    "                logger.warning(f\"macOS에서 '{font_name}' 폰트를 찾을 수 없습니다. 다른 한글 폰트를 확인해주세요.\")\n",
    "\n",
    "        elif sys.platform.startswith(\"linux\"):  # Linux\n",
    "            font_path_linux = None\n",
    "            nanum_fonts = [f for f in fm.fontManager.ttflist if 'NanumGothic' in f.name]\n",
    "            if nanum_fonts:\n",
    "                font_path_linux = nanum_fonts[0].fname \n",
    "                font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                plt.rc(\"font\", family=font_name)\n",
    "                logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "            else: \n",
    "                font_paths_linux_fallback = [\n",
    "                    \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\",\n",
    "                    \"/usr/share/fonts/nanum/NanumGothic.ttf\",\n",
    "                ]\n",
    "                for path_option in font_paths_linux_fallback:\n",
    "                    if os.path.exists(path_option):\n",
    "                        font_path_linux = path_option\n",
    "                        break\n",
    "                if font_path_linux:\n",
    "                    font_name = fm.FontProperties(fname=font_path_linux).get_name()\n",
    "                    plt.rc(\"font\", family=font_name)\n",
    "                    logger.info(f\"Linux에서 '{font_name}' (경로: {font_path_linux}) 폰트를 설정했습니다.\")\n",
    "                else:\n",
    "                    logger.error(\"Linux에서 NanumGothic 폰트를 찾을 수 없습니다. 'sudo apt-get install fonts-nanum*'으로 설치해주세요.\")\n",
    "        else:\n",
    "            logger.warning(f\"지원되지 않는 OS 플랫폼({sys.platform})입니다. 한글 폰트가 제대로 설정되지 않을 수 있습니다.\")\n",
    "        plt.rc(\"axes\", unicode_minus=False)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"한글 폰트 설정 중 오류 발생: {e}\")\n",
    "        logger.warning(\"기본 폰트로 시도합니다. 한글이 깨질 수 있습니다.\")\n",
    "\n",
    "# AdvancedBlending 클래스 (이전 코드에서 가져옴)\n",
    "class AdvancedBlending:\n",
    "    \"\"\"정교한 블렌딩 기법을 적용한 Copy-Paste\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def feather_edges(mask, feather_amount=10):\n",
    "        \"\"\"마스크 가장자리를 부드럽게 페더링\"\"\"\n",
    "        if mask is None or mask.size == 0:\n",
    "            logger.warning(\"페더링할 마스크가 비어있습니다.\")\n",
    "            return mask\n",
    "        if np.all(mask == 0): \n",
    "            return mask.astype(float) \n",
    "            \n",
    "        binary_mask = (mask > 0).astype(np.uint8) \n",
    "        dist_transform = distance_transform_edt(binary_mask)\n",
    "        feather_amount_safe = max(feather_amount, 1e-5)\n",
    "        feathered = np.minimum(dist_transform / feather_amount_safe, 1.0)\n",
    "        return feathered\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_blend(obj_img, background, obj_binary_mask, center_coords):\n",
    "        \"\"\"포아송 블렌딩 (Seamless Cloning)\"\"\"\n",
    "        if obj_img is None or obj_img.size == 0: return background\n",
    "        if background is None or background.size == 0: return background\n",
    "        if obj_binary_mask is None or obj_binary_mask.size == 0: return background\n",
    "\n",
    "        mask_for_poisson = (obj_binary_mask > 0).astype(np.uint8) * 255\n",
    "        \n",
    "        if np.sum(mask_for_poisson) == 0:\n",
    "            logger.warning(\"포아송 블렌딩을 위한 마스크가 비어있습니다. 원본 배경을 반환합니다.\")\n",
    "            return background.copy()\n",
    "\n",
    "        try:\n",
    "            # seamlessClone은 입력 이미지와 마스크의 크기가 같아야 함\n",
    "            if obj_img.shape[:2] != mask_for_poisson.shape[:2]:\n",
    "                logger.warning(f\"Poisson Blend: 객체 이미지({obj_img.shape[:2]})와 마스크({mask_for_poisson.shape[:2]}) 크기가 다릅니다. 마스크를 객체 크기로 조정합니다.\")\n",
    "                mask_for_poisson = cv2.resize(mask_for_poisson, (obj_img.shape[1], obj_img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # center_coords가 이미지 경계 내에 있는지 확인 및 조정\n",
    "            h_bg, w_bg = background.shape[:2]\n",
    "            h_obj, w_obj = obj_img.shape[:2]\n",
    "            \n",
    "            if not (0 <= center_coords[0] < w_bg and 0 <= center_coords[1] < h_bg):\n",
    "                logger.error(f\"Poisson Blend: 중심점 {center_coords}이 배경 크기 {background.shape[:2]} 밖에 있습니다.\")\n",
    "                return background.copy()\n",
    "\n",
    "\n",
    "            result = cv2.seamlessClone(\n",
    "                obj_img, \n",
    "                background, \n",
    "                mask_for_poisson, \n",
    "                center_coords, \n",
    "                cv2.NORMAL_CLONE \n",
    "            )\n",
    "            return result\n",
    "        except cv2.error as e:\n",
    "            logger.error(f\"포아송 블렌딩 오류: {e}. 객체 크기: {obj_img.shape}, 마스크 크기: {mask_for_poisson.shape}, 배경 크기: {background.shape}, 중심: {center_coords}\")\n",
    "            return background.copy()\n",
    "\n",
    "    @staticmethod\n",
    "    def multiband_blend(background_roi, obj_img_aligned, obj_mask_aligned_0_1_float_3ch, levels=4):\n",
    "        \"\"\"멀티밴드 블렌딩 (Laplacian Pyramid)\"\"\"\n",
    "        if background_roi is None or obj_img_aligned is None or obj_mask_aligned_0_1_float_3ch is None or \\\n",
    "           background_roi.size == 0 or obj_img_aligned.size == 0 or obj_mask_aligned_0_1_float_3ch.size == 0:\n",
    "            logger.warning(\"멀티밴드 블렌딩 입력값이 유효하지 않습니다.\")\n",
    "            return background_roi \n",
    "        \n",
    "        if background_roi.shape != obj_img_aligned.shape or background_roi.shape != obj_mask_aligned_0_1_float_3ch.shape:\n",
    "            logger.warning(\"멀티밴드 블렌딩: 입력 이미지/마스크 크기가 일치하지 않습니다.\")\n",
    "            return background_roi\n",
    "\n",
    "\n",
    "        gpA = [background_roi.astype(np.float32)] \n",
    "        gpB = [obj_img_aligned.astype(np.float32)] \n",
    "        gpM = [obj_mask_aligned_0_1_float_3ch.astype(np.float32)] \n",
    "\n",
    "        current_levels = 0\n",
    "        for i in range(levels):\n",
    "            if gpA[i].shape[0] < 2 or gpA[i].shape[1] < 2 or \\\n",
    "               gpB[i].shape[0] < 2 or gpB[i].shape[1] < 2 or \\\n",
    "               gpM[i].shape[0] < 2 or gpM[i].shape[1] < 2:\n",
    "                logger.warning(f\"멀티밴드 블렌딩 중 피라미드 레벨 {i+1}에서 이미지 크기가 너무 작아 현재 레벨({i})까지만 처리합니다.\")\n",
    "                levels = i \n",
    "                break\n",
    "            gpA.append(cv2.pyrDown(gpA[i]))\n",
    "            gpB.append(cv2.pyrDown(gpB[i]))\n",
    "            gpM.append(cv2.pyrDown(gpM[i]))\n",
    "            current_levels +=1\n",
    "        \n",
    "        if current_levels == 0 and levels > 0 : \n",
    "             logger.warning(\"멀티밴드 블렌딩: 이미지 크기가 너무 작아 피라미드를 생성할 수 없습니다. 단순 알파 블렌딩으로 대체합니다.\")\n",
    "             blended_roi_content = background_roi * (1 - obj_mask_aligned_0_1_float_3ch) + obj_img_aligned * obj_mask_aligned_0_1_float_3ch\n",
    "             return np.clip(blended_roi_content, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        lpA = [gpA[levels]]\n",
    "        lpB = [gpB[levels]]\n",
    "        for i in range(levels, 0, -1):\n",
    "            size = (gpA[i-1].shape[1], gpA[i-1].shape[0])\n",
    "            lpA.append(cv2.subtract(gpA[i-1], cv2.pyrUp(gpA[i], dstsize=size)))\n",
    "            lpB.append(cv2.subtract(lpB[i-1], cv2.pyrUp(lpB[i], dstsize=size))) # Changed from gpB[i-1] to lpB[i-1] as it was causing error.\n",
    "        \n",
    "        LS = []\n",
    "        for i in range(levels + 1): \n",
    "            la_current = lpA[i]\n",
    "            lb_current = lpB[i]\n",
    "            gm_current = gpM[levels-i] \n",
    "            \n",
    "            if la_current.shape != gm_current.shape or lb_current.shape != gm_current.shape:\n",
    "                logger.warning(f\"멀티밴드 블렌드 중 레벨 {levels-i}에서 크기 불일치. 마스크 크기 조정 시도.\")\n",
    "                gm_current = cv2.resize(gm_current, (la_current.shape[1], la_current.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "                if gm_current.ndim == 2 and la_current.ndim == 3: \n",
    "                    gm_current = np.stack([gm_current]*3, axis=-1)\n",
    "\n",
    "            ls = la_current * (1.0 - gm_current) + lb_current * gm_current\n",
    "            LS.append(ls)\n",
    "        \n",
    "        ls_ = LS[0] \n",
    "        for i in range(1, levels + 1): \n",
    "            size = (LS[i].shape[1], LS[i].shape[0])\n",
    "            ls_ = cv2.add(cv2.pyrUp(ls_, dstsize=size), LS[i])\n",
    "        \n",
    "        return np.clip(ls_, 0, 255).astype(np.uint8)\n",
    "\n",
    "    def blend_object_onto_background(self, background_orig, obj_img_transformed, obj_mask_transformed_binary, \n",
    "                                     obj_points_transformed_abs, paste_x, paste_y, new_w, new_h,\n",
    "                                     blend_mode='advanced_alpha'):\n",
    "        output_image = background_orig.copy()\n",
    "        y_start, y_end = int(paste_y), int(paste_y + new_h)\n",
    "        x_start, x_end = int(paste_x), int(paste_x + new_w)\n",
    "\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        if y_start < 0 or x_start < 0 or y_end > h_bg or x_end > w_bg:\n",
    "            logger.error(f\"블렌딩 ROI가 이미지 경계를 벗어납니다. ROI: ({x_start},{y_start})-({x_end},{y_end}), BG: ({w_bg},{h_bg})\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        roi_background = output_image[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        if obj_img_transformed is None or obj_img_transformed.size == 0 or \\\n",
    "           obj_mask_transformed_binary is None or obj_mask_transformed_binary.size == 0:\n",
    "            logger.warning(\"블렌딩할 객체 이미지 또는 마스크가 비어있습니다.\")\n",
    "            return output_image, obj_points_transformed_abs\n",
    "\n",
    "        if roi_background.shape[:2] != obj_img_transformed.shape[:2]:\n",
    "            logger.debug(f\"블렌딩 전 ROI({roi_background.shape[:2]})와 객체({obj_img_transformed.shape[:2]}) 크기 불일치. 객체/마스크를 ROI 크기로 조정.\")\n",
    "            obj_img_transformed = cv2.resize(obj_img_transformed, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "            obj_mask_transformed_binary = cv2.resize(obj_mask_transformed_binary, (roi_background.shape[1], roi_background.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "        harmonized_obj_img = obj_img_transformed.copy()\n",
    "        if blend_mode in ['advanced_alpha', 'color_match_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "            try:\n",
    "                obj_lab = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                roi_lab = cv2.cvtColor(roi_background, cv2.COLOR_BGR2LAB).astype(np.float32)\n",
    "                obj_pixels_lab = obj_lab[obj_mask_transformed_binary > 0]\n",
    "                if obj_pixels_lab.size > 0:\n",
    "                    obj_mean = np.mean(obj_pixels_lab, axis=0); obj_std = np.std(obj_pixels_lab, axis=0)\n",
    "                    roi_mean = np.mean(roi_lab, axis=(0, 1)); roi_std = np.std(roi_lab, axis=(0, 1))\n",
    "                    for i in range(3):\n",
    "                        obj_lab[:, :, i] = np.clip(\n",
    "                            (obj_lab[:, :, i] - obj_mean[i]) * (roi_std[i] / (obj_std[i] + 1e-5)) + roi_mean[i],\n",
    "                            0, 255 \n",
    "                        )\n",
    "                    harmonized_obj_img = cv2.cvtColor(obj_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "                else: logger.debug(\"색상 조화를 위한 객체 픽셀이 없습니다.\")\n",
    "            except cv2.error as e: logger.warning(f\"색상 조화 중 OpenCV 오류: {e}\")\n",
    "\n",
    "            if blend_mode in ['advanced_alpha', 'poisson_harmonized', 'multiband_harmonized']:\n",
    "                try:\n",
    "                    roi_gray = cv2.cvtColor(roi_background, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_gray = cv2.cvtColor(harmonized_obj_img, cv2.COLOR_BGR2GRAY)\n",
    "                    obj_pixels_gray = obj_gray[obj_mask_transformed_binary > 0]\n",
    "                    if obj_pixels_gray.size > 0 and np.mean(obj_pixels_gray) > 1e-5 :\n",
    "                        brightness_ratio = np.mean(roi_gray) / (np.mean(obj_pixels_gray) + 1e-5)\n",
    "                        brightness_ratio = np.clip(brightness_ratio, 0.7, 1.5) \n",
    "                        harmonized_obj_img = cv2.convertScaleAbs(harmonized_obj_img, alpha=brightness_ratio, beta=0)\n",
    "                    else: logger.debug(\"조명 조화를 위한 객체 픽셀이 없거나 평균 밝기가 0에 가깝습니다.\")\n",
    "                except cv2.error as e: logger.warning(f\"조명 조화 중 OpenCV 오류: {e}\")\n",
    "        \n",
    "        if blend_mode == 'poisson' or blend_mode == 'poisson_harmonized':\n",
    "            center_in_bg_abs = (x_start + new_w // 2, y_start + new_h // 2)\n",
    "            output_image = self.poisson_blend(harmonized_obj_img, output_image, obj_mask_transformed_binary, center_in_bg_abs)\n",
    "        \n",
    "        elif blend_mode == 'multiband' or blend_mode == 'multiband_harmonized':\n",
    "            mask_0_1_float_3ch = np.stack([obj_mask_transformed_binary.astype(float)/255.0]*3, axis=-1)\n",
    "            blended_roi_content = self.multiband_blend(roi_background, harmonized_obj_img, mask_0_1_float_3ch)\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content\n",
    "\n",
    "        else: \n",
    "            if blend_mode == 'simple_alpha':\n",
    "                alpha_mask_0_1_float = cv2.GaussianBlur(obj_mask_transformed_binary, (5,5), 0).astype(float) / 255.0\n",
    "            else: \n",
    "                feather_amount = max(3, int(min(new_h, new_w) * 0.03)) \n",
    "                mask_feathered = self.feather_edges(obj_mask_transformed_binary, feather_amount)\n",
    "                blur_ksize = max(3, 2 * int(min(new_h, new_w) * 0.02) + 1) \n",
    "                mask_blur = cv2.GaussianBlur(mask_feathered, (blur_ksize, blur_ksize), 0)\n",
    "                final_alpha_mask_0_1_float = np.clip(mask_blur, 0, 1)\n",
    "                if blend_mode == 'advanced_alpha':\n",
    "                    grad_x = cv2.Sobel(mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "                    grad_y = cv2.Sobel(mask_blur, cv2.CV_64F, 0, 1, ksize=3)\n",
    "                    gradient = np.sqrt(grad_x**2 + grad_y**2)\n",
    "                    if np.max(gradient) > 1e-5:\n",
    "                        gradient = gradient / np.max(gradient)\n",
    "                        final_alpha_mask_0_1_float = final_alpha_mask_0_1_float * (1 - gradient * 0.2) \n",
    "                        final_alpha_mask_0_1_float = np.clip(final_alpha_mask_0_1_float, 0, 1)\n",
    "                alpha_mask_0_1_float = final_alpha_mask_0_1_float\n",
    "\n",
    "            alpha_mask_3ch = np.stack([alpha_mask_0_1_float] * 3, axis=-1)\n",
    "            blended_roi_content = roi_background * (1 - alpha_mask_3ch) + harmonized_obj_img * alpha_mask_3ch\n",
    "            output_image[y_start:y_end, x_start:x_end] = blended_roi_content.astype(np.uint8)\n",
    "\n",
    "            if blend_mode == 'advanced_alpha':\n",
    "                try:\n",
    "                    shadow_kernel_size = max(3, int(min(new_h, new_w) * 0.08)) \n",
    "                    shadow_kernel_size = shadow_kernel_size if shadow_kernel_size % 2 != 0 else shadow_kernel_size + 1 \n",
    "                    dilated_mask = cv2.dilate(obj_mask_transformed_binary, np.ones((shadow_kernel_size//2, shadow_kernel_size//2), np.uint8), iterations=1)\n",
    "                    shadow_alpha_mask = cv2.GaussianBlur(dilated_mask, (shadow_kernel_size, shadow_kernel_size), 0)\n",
    "                    shadow_alpha_mask = shadow_alpha_mask.astype(float) / 255.0 * 0.15 \n",
    "                    shadow_region_float = output_image[y_start:y_end, x_start:x_end].astype(float)\n",
    "                    effective_shadow_alpha = np.clip(shadow_alpha_mask - (obj_mask_transformed_binary.astype(float)/255.0), 0, 1)\n",
    "                    for c in range(3):\n",
    "                        shadow_region_float[:,:,c] *= (1 - effective_shadow_alpha * 0.7) \n",
    "                    output_image[y_start:y_end, x_start:x_end] = np.clip(shadow_region_float, 0, 255).astype(np.uint8)\n",
    "                except Exception as e: logger.warning(f\"그림자 효과 적용 중 오류: {e}\")\n",
    "        return output_image, obj_points_transformed_abs\n",
    "\n",
    "\n",
    "class OptimizedYOLOAugmentation:\n",
    "    def __init__(self, images_dir, labels_dir, output_dir, class_names=None):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_images_dir = self.output_dir / 'images'\n",
    "        self.output_labels_dir = self.output_dir / 'labels'\n",
    "        self.output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.class_names = class_names or ['ac', 'lc', 'pc', 'tc', 'ph']\n",
    "        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}\n",
    "        self.class_objects = defaultdict(list)\n",
    "        self.original_class_counts = Counter()\n",
    "        self.augmented_class_counts = Counter() \n",
    "        self.min_object_size = 30\n",
    "        self.max_object_ratio = 0.4\n",
    "        self.blender = AdvancedBlending()\n",
    "\n",
    "    def analyze_dataset(self):\n",
    "        logger.info(\"데이터셋 분석 중...\")\n",
    "        self.original_class_counts.clear()\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다.\")\n",
    "            return self.original_class_counts\n",
    "        total_images_processed = 0\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    total_images_processed +=1\n",
    "                    for shape in data['shapes']:\n",
    "                        if 'label' in shape and shape['label'] in self.class_to_idx:\n",
    "                            self.original_class_counts[shape['label']] += 1\n",
    "                        elif 'label' in shape:\n",
    "                            logger.warning(f\"라벨 파일 '{json_file.name}'에 정의되지 않은 클래스 '{shape['label']}'가 있습니다.\")\n",
    "            except json.JSONDecodeError: logger.error(f\"JSON 파싱 오류: {json_file}\")\n",
    "            except Exception as e: logger.error(f\"파일 분석 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {total_images_processed}개의 이미지 라벨 분석 완료.\")\n",
    "        logger.info(f\"원본 클래스별 분포: {dict(self.original_class_counts)}\")\n",
    "        return self.original_class_counts\n",
    "    \n",
    "    def calculate_optimized_weights(self):\n",
    "        if not self.original_class_counts:\n",
    "            logger.warning(\"원본 클래스 카운트가 없어 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        total_objects = sum(self.original_class_counts.values())\n",
    "        num_classes_with_objects = len([c_name for c_name, count in self.original_class_counts.items() if count > 0])\n",
    "\n",
    "        if total_objects == 0 or num_classes_with_objects == 0:\n",
    "            logger.warning(\"객체가 없거나 객체가 있는 클래스가 없어 유효한 가중치를 계산할 수 없습니다. 모든 클래스 동일 가중치(1.0)를 사용합니다.\")\n",
    "            return {cn: 1.0 for cn in self.class_names}\n",
    "        \n",
    "        weights = {}\n",
    "        for class_name in self.class_names: \n",
    "            count = self.original_class_counts.get(class_name, 0)\n",
    "            if count > 0: \n",
    "                weight = np.sqrt(total_objects / (num_classes_with_objects * count))\n",
    "            else: \n",
    "                weight = 0 \n",
    "            weights[class_name] = weight\n",
    "        \n",
    "        valid_weights = [w for w in weights.values() if w > 0]\n",
    "        max_calculated_weight = max(valid_weights) if valid_weights else 1.0 \n",
    "        \n",
    "        for class_name in self.class_names:\n",
    "            if weights[class_name] == 0: \n",
    "                weights[class_name] = max_calculated_weight * 1.5 \n",
    "        \n",
    "        logger.info(f\"최적화된 증강 가중치: {weights}\")\n",
    "        return weights\n",
    "\n",
    "    def intelligent_copy_paste_with_advanced_blending(self, background_orig, \n",
    "                                                      class_weights, \n",
    "                                                      num_pastes_range=(1, 4), \n",
    "                                                      difficulty_level='medium',\n",
    "                                                      blend_mode='advanced_alpha'):\n",
    "        if not any(self.class_objects.values()):\n",
    "            logger.warning(\"Copy-Paste를 위한 추출된 객체가 없습니다.\")\n",
    "            return background_orig, [] \n",
    "\n",
    "        output_image = background_orig.copy()\n",
    "        h_bg, w_bg = output_image.shape[:2]\n",
    "        pasted_shapes_info = [] \n",
    "\n",
    "        min_pastes, max_pastes = num_pastes_range\n",
    "        if difficulty_level == 'easy':\n",
    "            num_pastes_actual = random.randint(min_pastes, max(min_pastes, (min_pastes + max_pastes) // 3))\n",
    "        elif difficulty_level == 'medium':\n",
    "            num_pastes_actual = random.randint(min_pastes, max_pastes)\n",
    "        else: \n",
    "            num_pastes_actual = random.randint(max_pastes, int(max_pastes * 1.5))\n",
    "            num_pastes_actual = min(num_pastes_actual, 8) \n",
    "        \n",
    "        if not class_weights or not any(v > 0 for v in class_weights.values()):\n",
    "            logger.warning(\"유효한 클래스 가중치가 없어 Copy-Paste를 건너<0xEB><0x8A><0xB5>니다.\")\n",
    "            return output_image, []\n",
    "\n",
    "        classes_with_objects_and_weights = [cn for cn in class_weights if class_weights.get(cn, 0) > 0 and self.class_objects.get(cn)]\n",
    "        if not classes_with_objects_and_weights:\n",
    "            logger.warning(\"붙여넣을 수 있는 객체가 있는 클래스가 없거나 가중치가 없습니다.\")\n",
    "            return output_image, []\n",
    "        weights_for_choice = [class_weights[cn] for cn in classes_with_objects_and_weights]\n",
    "\n",
    "        occupied_bboxes = [] \n",
    "        successfully_pasted_count = 0\n",
    "\n",
    "        for _ in range(num_pastes_actual):\n",
    "            try:\n",
    "                selected_class = random.choices(classes_with_objects_and_weights, weights=weights_for_choice)[0]\n",
    "            except IndexError:\n",
    "                logger.warning(\"가중치 기반 클래스 선택 실패. 건너<0xEB><0x8A><0xB5>니다.\")\n",
    "                continue\n",
    "            \n",
    "            if not self.class_objects[selected_class]: continue\n",
    "\n",
    "            obj_data = random.choice(self.class_objects[selected_class])\n",
    "            obj_img_to_paste = obj_data['image'] \n",
    "            obj_mask_to_paste = obj_data['mask'] \n",
    "            obj_points_relative = obj_data['points'].copy() \n",
    "\n",
    "            if obj_img_to_paste is None or obj_img_to_paste.size == 0 or \\\n",
    "               obj_mask_to_paste is None or obj_mask_to_paste.size == 0:\n",
    "                logger.warning(f\"선택된 객체 '{selected_class}'의 이미지 또는 마스크가 비어있습니다.\")\n",
    "                continue\n",
    "\n",
    "            h_obj_orig, w_obj_orig = obj_img_to_paste.shape[:2]\n",
    "\n",
    "            current_scale = random.uniform(0.6, 1.4)\n",
    "            current_rotation = 0\n",
    "            if random.random() < 0.4: current_rotation = random.uniform(-20, 20)\n",
    "            \n",
    "            transform_center = (w_obj_orig // 2, h_obj_orig // 2)\n",
    "            M_transform = cv2.getRotationMatrix2D(transform_center, current_rotation, current_scale)\n",
    "            \n",
    "            cos_t = np.abs(M_transform[0, 0]); sin_t = np.abs(M_transform[0, 1])\n",
    "            new_obj_w = int((h_obj_orig * sin_t) + (w_obj_orig * cos_t))\n",
    "            new_obj_h = int((h_obj_orig * cos_t) + (w_obj_orig * sin_t))\n",
    "\n",
    "            if new_obj_w == 0 or new_obj_h == 0: continue\n",
    "\n",
    "            M_transform[0, 2] += (new_obj_w / 2) - transform_center[0]\n",
    "            M_transform[1, 2] += (new_obj_h / 2) - transform_center[1]\n",
    "            \n",
    "            final_obj_img = cv2.warpAffine(obj_img_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))\n",
    "            final_obj_mask_binary = cv2.warpAffine(obj_mask_to_paste, M_transform, (new_obj_w, new_obj_h), flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT, borderValue=(0))\n",
    "            \n",
    "            ones_homo = np.ones((obj_points_relative.shape[0], 1))\n",
    "            points_homo = np.hstack([obj_points_relative, ones_homo])\n",
    "            final_obj_points_relative_transformed = (M_transform @ points_homo.T).T \n",
    "\n",
    "            if new_obj_h >= h_bg or new_obj_w >= w_bg: continue\n",
    "            \n",
    "            if random.random() < 0.3: \n",
    "                color_aug = A.Compose([\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=1.0),\n",
    "                    A.HueSaturationValue(hue_shift_limit=12, sat_shift_limit=18, val_shift_limit=12, p=1.0)\n",
    "                ])\n",
    "                final_obj_img = color_aug(image=final_obj_img)['image']\n",
    "\n",
    "            paste_margin = max(5, int(0.01 * min(h_bg, w_bg)))\n",
    "            if w_bg - new_obj_w - 2 * paste_margin <= 0 or h_bg - new_obj_h - 2 * paste_margin <= 0: continue\n",
    "            \n",
    "            found_position = False\n",
    "            for _ in range(30): \n",
    "                current_paste_x = random.randint(paste_margin, w_bg - new_obj_w - paste_margin)\n",
    "                current_paste_y = random.randint(paste_margin, h_bg - new_obj_h - paste_margin)\n",
    "                current_bbox_abs = [current_paste_x, current_paste_y, current_paste_x + new_obj_w, current_paste_y + new_obj_h]\n",
    "                \n",
    "                if any(self.calculate_iou(current_bbox_abs, occ_bbox) > 0.15 for occ_bbox in occupied_bboxes):\n",
    "                    continue\n",
    "                \n",
    "                output_image, _ = self.blender.blend_object_onto_background(\n",
    "                    output_image, final_obj_img, final_obj_mask_binary, \n",
    "                    None, \n",
    "                    current_paste_x, current_paste_y, new_obj_w, new_obj_h,\n",
    "                    blend_mode=blend_mode\n",
    "                )\n",
    "                \n",
    "                abs_points_for_label = (final_obj_points_relative_transformed + np.array([current_paste_x, current_paste_y])).astype(np.int32).tolist()\n",
    "                pasted_shapes_info.append({\n",
    "                    'label': selected_class,\n",
    "                    'points': abs_points_for_label, \n",
    "                    'group_id': None, 'shape_type': 'polygon', 'flags': {}\n",
    "                })\n",
    "                occupied_bboxes.append(current_bbox_abs)\n",
    "                successfully_pasted_count += 1\n",
    "                found_position = True\n",
    "                break\n",
    "        \n",
    "        logger.debug(f\"{successfully_pasted_count}개의 객체(Advanced Blending) 붙여넣기 완료 (시도: {num_pastes_actual}개).\")\n",
    "        return output_image, pasted_shapes_info\n",
    "    \n",
    "    def apply_geometric_transform(self, image, shapes, transform_prob=0.8):\n",
    "        \"\"\"\n",
    "        이미지, 마스크 및 모든 shape의 폴리곤 좌표에 기하 변형(Cutout, Elastic, Grid)을 적용합니다.\n",
    "        shapes: [{'label': 'name', 'points': [[x1,y1], ...], ...}, ...]\n",
    "        \"\"\"\n",
    "        if random.random() >= transform_prob: \n",
    "            return image, shapes\n",
    "\n",
    "        # Cutout은 keypoints를 지원하지 않으므로, 이미지에만 별도로 적용합니다.\n",
    "        # Cutout을 먼저 적용\n",
    "        cutout_transform = A.Compose([\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.7) # p=확률, num_holes=자르는 사각형 개수, max_h/w_size=최대 크기, fill_value=채울 색상\n",
    "        ])\n",
    "        \n",
    "        # Cutout을 먼저 적용\n",
    "        transformed_image = cutout_transform(image=image)['image']\n",
    "\n",
    "        # 이후 ElasticTransform과 GridDistortion 적용 (keypoints 포함)\n",
    "        geometric_transform_pipeline = A.Compose([\n",
    "            A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7, \n",
    "                               border_mode=cv2.BORDER_REFLECT_101),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7, \n",
    "                             border_mode=cv2.BORDER_REFLECT_101),\n",
    "        ], keypoint_params=A.KeypointParams(format='xy', label_fields=['shape_indices'], remove_invisible=False))\n",
    "\n",
    "        all_keypoints_flat = []\n",
    "        keypoint_shape_indices = [] \n",
    "        points_per_shape_count = [] \n",
    "\n",
    "        for idx, shape_dict in enumerate(shapes):\n",
    "            points = shape_dict.get('points', [])\n",
    "            if points and len(points) >=3 : \n",
    "                all_keypoints_flat.extend(points) \n",
    "                keypoint_shape_indices.extend([idx] * len(points)) \n",
    "                points_per_shape_count.append(len(points))\n",
    "            else:\n",
    "                points_per_shape_count.append(0) \n",
    "\n",
    "        if not all_keypoints_flat: \n",
    "            # 키포인트가 없으면 기하 변형은 이미지에만 적용\n",
    "            img_only_geometric_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=0.7,\n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=0.7,\n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_geometric_pipeline(image=transformed_image)['image'] # 이미 Cutout 적용된 이미지에 적용\n",
    "            return transformed_image, shapes \n",
    "\n",
    "        try:\n",
    "            # Cutout이 적용된 이미지와 함께 keypoints에 기하 변형 적용\n",
    "            transformed_data = geometric_transform_pipeline(image=transformed_image, keypoints=all_keypoints_flat, shape_indices=keypoint_shape_indices)\n",
    "            transformed_image = transformed_data['image']\n",
    "            transformed_keypoints_flat = transformed_data['keypoints']\n",
    "\n",
    "            new_shapes = []\n",
    "            current_kp_idx = 0\n",
    "            for shape_idx, original_shape_dict in enumerate(shapes):\n",
    "                num_points_for_this_shape = points_per_shape_count[shape_idx]\n",
    "                new_shape = original_shape_dict.copy()\n",
    "                if num_points_for_this_shape > 0:\n",
    "                    shape_keypoints = transformed_keypoints_flat[current_kp_idx : current_kp_idx + num_points_for_this_shape]\n",
    "                    new_shape['points'] = np.array(shape_keypoints, dtype=np.int32).tolist()\n",
    "                    current_kp_idx += num_points_for_this_shape\n",
    "                else: \n",
    "                    new_shape['points'] = [] \n",
    "                new_shapes.append(new_shape)\n",
    "            \n",
    "            return transformed_image, new_shapes\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"기하 변형 중 오류 발생: {e}. 이미지 변형만 시도합니다.\")\n",
    "            img_only_geometric_pipeline = A.Compose([\n",
    "                A.ElasticTransform(alpha=100, sigma=100 * 0.06, alpha_affine=100 * 0.04, p=1.0, \n",
    "                                   border_mode=cv2.BORDER_REFLECT_101),\n",
    "                A.GridDistortion(num_steps=5, distort_limit=0.25, p=1.0, \n",
    "                                 border_mode=cv2.BORDER_REFLECT_101),\n",
    "            ])\n",
    "            transformed_image = img_only_geometric_pipeline(image=transformed_image)['image'] # 이미 Cutout 적용된 이미지에 적용\n",
    "            return transformed_image, shapes \n",
    "\n",
    "\n",
    "    def calculate_iou(self, box1, box2):\n",
    "        x1_inter = max(box1[0], box2[0])\n",
    "        y1_inter = max(box1[1], box2[1])\n",
    "        x2_inter = min(box1[2], box2[2])\n",
    "        y2_inter = min(box1[3], box2[3])\n",
    "        intersection_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "        if intersection_area == 0: return 0.0\n",
    "        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "        union_area = area1 + area2 - intersection_area\n",
    "        return intersection_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "    def extract_objects_from_dataset(self):\n",
    "        logger.info(\"고품질 객체 추출 중...\")\n",
    "        self.class_objects.clear()\n",
    "        extracted_count = 0\n",
    "        json_files = list(self.labels_dir.glob('*.json'))\n",
    "        if not json_files:\n",
    "            logger.warning(f\"{self.labels_dir} 에서 JSON 라벨 파일을 찾을 수 없습니다. 객체 추출을 건너<0xEB><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        for idx, json_file in enumerate(json_files):\n",
    "            if idx % 50 == 0: logger.info(f\"객체 추출 진행: {idx}/{len(json_files)}\")\n",
    "            try:\n",
    "                base_name = json_file.stem\n",
    "                img_file, _ = self._find_image_file(base_name)\n",
    "                if not img_file:\n",
    "                    logger.warning(f\"객체 추출을 위한 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "                image = cv2.imread(str(img_file))\n",
    "                if image is None:\n",
    "                    logger.warning(f\"이미지 로드 실패: {img_file}\")\n",
    "                    continue\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' not in data: continue\n",
    "                for shape in data['shapes']:\n",
    "                    if shape.get('shape_type') != 'polygon' or 'label' not in shape: continue\n",
    "                    label = shape['label']\n",
    "                    if label not in self.class_to_idx:\n",
    "                        logger.debug(f\"객체 추출 중 정의되지 않은 라벨 '{label}' 발견: {json_file.name}\")\n",
    "                        continue\n",
    "                    points_list = shape.get('points', [])\n",
    "                    if not points_list or len(points_list) < 3: continue\n",
    "                    points = np.array(points_list, dtype=np.int32)\n",
    "                    x, y, w, h = cv2.boundingRect(points)\n",
    "                    if not (self.min_object_size <= w < image.shape[1] * self.max_object_ratio and \\\n",
    "                            self.min_object_size <= h < image.shape[0] * self.max_object_ratio):\n",
    "                        continue\n",
    "                    if h == 0: continue\n",
    "                    aspect_ratio = w / h\n",
    "                    if not (0.2 < aspect_ratio < 5.0): continue\n",
    "                    obj_region_mask_full = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "                    cv2.fillPoly(obj_region_mask_full, [points], 255)\n",
    "                    obj_img_cropped = image[y:y+h, x:x+w].copy()\n",
    "                    obj_mask_cropped = obj_region_mask_full[y:y+h, x:x+w].copy() \n",
    "                    obj_img_masked = cv2.bitwise_and(obj_img_cropped, obj_img_cropped, mask=obj_mask_cropped)\n",
    "                    relative_points = points - np.array([x, y])\n",
    "                    self.class_objects[label].append({\n",
    "                        'image': obj_img_masked,    \n",
    "                        'mask': obj_mask_cropped,  \n",
    "                        'points': relative_points,  \n",
    "                    })\n",
    "                    extracted_count += 1\n",
    "            except Exception as e: logger.exception(f\"객체 추출 중 오류: {json_file} - {e}\")\n",
    "        logger.info(f\"총 {extracted_count}개의 객체 추출 완료.\")\n",
    "        for class_name, objects in self.class_objects.items():\n",
    "            logger.info(f\"  - {class_name}: {len(objects)}개\")\n",
    "\n",
    "    def _find_image_file(self, base_name):\n",
    "        possible_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', \n",
    "                               '.JPG', '.JPEG', '.PNG', '.BMP', '.TIFF']\n",
    "        for ext in possible_extensions:\n",
    "            potential_file = self.images_dir / f\"{base_name}{ext}\"\n",
    "            if potential_file.exists():\n",
    "                return potential_file, ext\n",
    "        return None, None\n",
    "\n",
    "    def augment_dataset_pipeline(self, pipeline_type=\"copy_paste_first\", \n",
    "                                 target_total_images=2400, \n",
    "                                 elastic_grid_prob=0.8, # 이 값은 Cutout과 Elastic/Grid 둘 다에 적용되는 확률\n",
    "                                 copy_paste_prob=0.9, \n",
    "                                 num_pastes_range=(1,3),\n",
    "                                 blend_mode='advanced_alpha'):\n",
    "        logger.info(f\"'{pipeline_type}' (블렌드: {blend_mode}) 파이프라인으로 데이터셋 증강 시작: 목표 {target_total_images}장\")\n",
    "\n",
    "        self.analyze_dataset()\n",
    "        if not self.original_class_counts:\n",
    "            logger.error(\"원본 데이터셋 분석 실패. 증강 중단.\")\n",
    "            return\n",
    "\n",
    "        class_weights = self.calculate_optimized_weights()\n",
    "        if not class_weights:\n",
    "            logger.error(\"클래스 가중치 계산 실패. 증강 중단.\")\n",
    "            return\n",
    "        \n",
    "        self.extract_objects_from_dataset()\n",
    "\n",
    "        logger.info(\"원본 파일 복사 중...\")\n",
    "        json_files_original = list(self.labels_dir.glob('*.json'))\n",
    "        original_image_count = len(json_files_original)\n",
    "\n",
    "        for json_file_idx, json_file in enumerate(json_files_original):\n",
    "            if json_file_idx % 100 == 0:\n",
    "                 logger.info(f\"원본 파일 복사 진행: {json_file_idx}/{len(json_files_original)}\")\n",
    "            base_name = json_file.stem\n",
    "            img_file, img_ext_found = self._find_image_file(base_name)\n",
    "            if img_file:\n",
    "                try:\n",
    "                    shutil.copy2(img_file, self.output_images_dir / img_file.name)\n",
    "                    shutil.copy2(json_file, self.output_labels_dir / json_file.name)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"원본 파일 복사 실패: {img_file} 또는 {json_file} - {e}\")\n",
    "            else:\n",
    "                logger.warning(f\"원본 이미지 파일을 찾지 못해 복사하지 못했습니다: {self.images_dir / base_name}\")\n",
    "\n",
    "        current_total_images = original_image_count\n",
    "        generated_augmented_count = 0\n",
    "        \n",
    "        difficulty_levels = ['easy', 'medium', 'hard']\n",
    "        difficulty_probs = [0.3, 0.5, 0.2]\n",
    "\n",
    "        while current_total_images < target_total_images:\n",
    "            random.shuffle(json_files_original)\n",
    "            for json_file_orig in json_files_original:\n",
    "                if current_total_images >= target_total_images: break\n",
    "\n",
    "                base_name = json_file_orig.stem\n",
    "                img_file_orig, img_ext = self._find_image_file(base_name)\n",
    "\n",
    "                if not img_file_orig:\n",
    "                    logger.warning(f\"증강을 위한 원본 이미지 파일 없음: {self.images_dir / base_name}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    image = cv2.imread(str(img_file_orig))\n",
    "                    if image is None:\n",
    "                        logger.warning(f\"이미지 로드 실패: {img_file_orig}\")\n",
    "                        continue\n",
    "                    \n",
    "                    with open(json_file_orig, 'r', encoding='utf-8') as f:\n",
    "                        label_data = json.load(f)\n",
    "                    \n",
    "                    original_shapes = label_data.get('shapes', []) \n",
    "                    augmented_image = image.copy()\n",
    "                    current_shapes = [s.copy() for s in original_shapes] \n",
    "\n",
    "                    difficulty = random.choices(difficulty_levels, difficulty_probs)[0]\n",
    "\n",
    "                    if pipeline_type == \"copy_paste_first\": \n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights,\n",
    "                                num_pastes_range=num_pastes_range,\n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"CPF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                        \n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"CPF: Cutout+Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "\n",
    "                    elif pipeline_type == \"elastic_grid_first\": # 이 부분이 변경됩니다.\n",
    "                        # apply_geometric_transform 함수 내에서 이미 Cutout이 Elastic/Grid보다 먼저 적용되도록 구현했으므로,\n",
    "                        # 여기서는 apply_geometric_transform을 단순히 호출하면 됩니다.\n",
    "                        augmented_image, current_shapes = self.apply_geometric_transform(\n",
    "                            augmented_image, current_shapes, transform_prob=elastic_grid_prob\n",
    "                        )\n",
    "                        logger.debug(f\"EGF: Cutout+Elastic/Grid 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "\n",
    "                        if random.random() < copy_paste_prob and any(self.class_objects.values()):\n",
    "                            pasted_bg, new_pasted_shapes = self.intelligent_copy_paste_with_advanced_blending(\n",
    "                                augmented_image.copy(), \n",
    "                                class_weights, \n",
    "                                num_pastes_range=num_pastes_range, \n",
    "                                difficulty_level=difficulty,\n",
    "                                blend_mode=blend_mode\n",
    "                            )\n",
    "                            augmented_image = pasted_bg\n",
    "                            current_shapes.extend(new_pasted_shapes) \n",
    "                            logger.debug(f\"EGF: Copy-Paste 적용 후 shapes 개수: {len(current_shapes)}\")\n",
    "                            \n",
    "                    else:\n",
    "                        logger.error(f\"알 수 없는 파이프라인 유형: {pipeline_type}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # 유효한 폴리곤만 필터링 (점이 3개 미만인 폴리곤은 유효하지 않음)\n",
    "                    current_shapes = [s for s in current_shapes if s.get('points') and len(s['points']) >= 3]\n",
    "\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "                    aug_base_name = f\"{base_name}_{pipeline_type}_{blend_mode}_{timestamp}_{random.randint(1000,9999)}\"\n",
    "                    aug_img_path = self.output_images_dir / f\"{aug_base_name}{img_ext}\" \n",
    "                    aug_label_path = self.output_labels_dir / f\"{aug_base_name}.json\"\n",
    "\n",
    "                    cv2.imwrite(str(aug_img_path), augmented_image)\n",
    "                    \n",
    "                    final_label_data = {\n",
    "                        \"version\": label_data.get(\"version\", \"5.0.0\"), \"flags\": label_data.get(\"flags\", {}),\n",
    "                        \"shapes\": current_shapes, \n",
    "                        \"imagePath\": aug_img_path.name, \"imageData\": None,\n",
    "                        \"imageHeight\": augmented_image.shape[0], \"imageWidth\": augmented_image.shape[1]\n",
    "                    }\n",
    "                    with open(aug_label_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(final_label_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "                    generated_augmented_count += 1\n",
    "                    current_total_images += 1\n",
    "                    if generated_augmented_count % 20 == 0: \n",
    "                        logger.info(f\"  - 생성된 증강 이미지 {generated_augmented_count}개 (총 {current_total_images}/{target_total_images}장)\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"증강 파이프라인 오류 ({pipeline_type}, {blend_mode}): {json_file_orig.name} - {e}\")\n",
    "        \n",
    "        logger.info(f\"'{pipeline_type}' ({blend_mode}) 파이프라인 최종 증강 완료: 원본 {original_image_count}장 + 증강 {generated_augmented_count}장 = 총 {current_total_images}장\")\n",
    "        self.visualize_augmentation_results()\n",
    "\n",
    "    def visualize_augmentation_results(self):\n",
    "        set_korean_font() \n",
    "        final_counts_from_output = Counter()\n",
    "        output_label_files = list(self.output_labels_dir.glob('*.json'))\n",
    "        if not output_label_files:\n",
    "            logger.warning(\"출력 디렉토리에 라벨 파일이 없어 시각화를 건너<0xEB><0x8A><0xB5>니다.\")\n",
    "            return\n",
    "        logger.info(f\"시각화를 위해 총 {len(output_label_files)}개의 출력 라벨 파일 분석 중...\")\n",
    "        for json_file in output_label_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "                if 'shapes' in data:\n",
    "                    for shape in data['shapes']:\n",
    "                        label = shape.get('label')\n",
    "                        if label and label in self.class_to_idx: \n",
    "                            final_counts_from_output[label] += 1\n",
    "            except Exception as e: logger.warning(f\"출력 라벨 파일 분석 오류: {json_file.name} - {e}\")\n",
    "        logger.info(f\"출력 파일 분석 기반 최종 클래스 분포: {dict(final_counts_from_output)}\")\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(17, 14))\n",
    "        fig.suptitle(\"데이터 증강 결과 분석\", fontsize=20, fontweight='bold', y=0.98)\n",
    "        classes = list(self.class_names)\n",
    "        original_obj_counts = [self.original_class_counts.get(c, 0) for c in classes]\n",
    "        final_obj_counts = [final_counts_from_output.get(c, 0) for c in classes]\n",
    "        x_indices = np.arange(len(classes))\n",
    "        bar_width = 0.35\n",
    "        rects1 = ax1.bar(x_indices - bar_width/2, original_obj_counts, bar_width, label='원본 객체 수', color='deepskyblue', alpha=0.9)\n",
    "        rects2 = ax1.bar(x_indices + bar_width/2, final_obj_counts, bar_width, label='증강 후 객체 수', color='salmon', alpha=0.9)\n",
    "        ax1.set_xlabel('클래스', fontsize=13); ax1.set_ylabel('객체 수', fontsize=13)\n",
    "        ax1.set_title('클래스별 객체 수 비교', fontsize=15); ax1.set_xticks(x_indices)\n",
    "        ax1.set_xticklabels(classes, rotation=45, ha=\"right\", fontsize=10); ax1.legend(fontsize=11)\n",
    "        ax1.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        for rect in rects1 + rects2:\n",
    "            h = rect.get_height()\n",
    "            ax1.text(rect.get_x() + rect.get_width()/2., h, f'{int(h)}', ha='center', va='bottom', fontsize=8)\n",
    "        increase_rates = [((f - o) / o * 100) if o > 0 else (float('inf') if f > 0 else 0) for o, f in zip(original_obj_counts, final_obj_counts)]\n",
    "        colors_bar = ['limegreen' if r >= 100 else 'gold' if r >= 0 else 'tomato' for r in increase_rates]\n",
    "        bars = ax2.bar(classes, increase_rates, color=colors_bar)\n",
    "        ax2.set_xlabel('클래스', fontsize=13); ax2.set_ylabel('객체 수 증가율 (%)', fontsize=13)\n",
    "        ax2.set_title('클래스별 객체 수 증가율', fontsize=15); ax2.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "        ax2.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "        for bar_idx, bar_item in enumerate(bars):\n",
    "            yval = bar_item.get_height()\n",
    "            ax2.text(bar_item.get_x() + bar_item.get_width()/2., yval, f'{yval:.0f}%' if yval != float('inf') else 'Inf', \n",
    "                     ha='center', va='bottom' if yval >=0 else 'top', fontsize=8)\n",
    "        if sum(final_obj_counts) > 0:\n",
    "            valid_labels = [classes[i] for i, v in enumerate(final_obj_counts) if v > 0]\n",
    "            valid_values = [v for v in final_obj_counts if v > 0]\n",
    "            ax3.pie(valid_values, labels=valid_labels, autopct='%1.1f%%', startangle=120,\n",
    "                    wedgeprops={'edgecolor': 'silver', 'linewidth': 0.7}, textprops={'fontsize': 9})\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15); ax3.axis('equal')\n",
    "        else:\n",
    "            ax3.text(0.5, 0.5, \"증강된 객체 없음\", ha='center', va='center', transform=ax3.transAxes)\n",
    "            ax3.set_title('최종 클래스 분포 (증강 후 객체 기준)', fontsize=15)\n",
    "        def gini_coefficient_calc(values):\n",
    "            vals = sorted(filter(lambda x: x > 0, values))\n",
    "            if not vals or len(vals) <= 1: return 0.0\n",
    "            n = len(vals); idx = np.arange(1, n + 1)\n",
    "            return (np.sum((2 * idx - n - 1) * np.array(vals))) / (n * sum(vals)) if sum(vals) > 0 else 0.0\n",
    "        gini_orig = gini_coefficient_calc(original_obj_counts)\n",
    "        gini_final = gini_coefficient_calc(final_obj_counts)\n",
    "        ax4.text(0.5, 0.85, '클래스 균형도 (Gini 계수)', ha='center', va='center', fontsize=15, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.65, f'원본 Gini: {gini_orig:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.55, f'증강 후 Gini: {gini_final:.3f}', ha='center', va='center', fontsize=13, transform=ax4.transAxes)\n",
    "        improvement_text_val, text_color_val = \"Gini 개선율: N/A\", 'dimgray'\n",
    "        if gini_orig > 1e-6 : \n",
    "            improvement_val = ((gini_orig - gini_final) / gini_orig * 100)\n",
    "            improvement_text_val = f'Gini 개선율: {improvement_val:.1f}%'\n",
    "            text_color_val = 'forestgreen' if improvement_val > 0 else ('tomato' if improvement_val < 0 else 'darkorange')\n",
    "        elif gini_orig <= 1e-6 and gini_final > 1e-6 : improvement_text_val, text_color_val = \"균형 악화됨\", 'tomato'\n",
    "        elif gini_orig <= 1e-6 and gini_final <= 1e-6 : improvement_text_val, text_color_val = \"완벽 균형 유지\", 'forestgreen'\n",
    "        ax4.text(0.5, 0.35, improvement_text_val, ha='center', va='center', fontsize=16, color=text_color_val, fontweight='bold', transform=ax4.transAxes)\n",
    "        ax4.text(0.5, 0.15, \"(Gini 계수는 0에 가까울수록 균형)\", ha='center', va='center', fontsize=10, style='italic', color='gray', transform=ax4.transAxes)\n",
    "        ax4.axis('off'); plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        save_path_fig = self.output_dir / f'augmentation_summary_{timestamp_str}.png'\n",
    "        try:\n",
    "            plt.savefig(save_path_fig, dpi=300, bbox_inches='tight')\n",
    "            logger.info(f\"시각화 요약 저장 완료: {save_path_fig}\")\n",
    "        except Exception as e: logger.error(f\"시각화 파일 저장 실패: {e}\")\n",
    "        plt.close(fig)\n",
    "        logger.info(\"\\n=== 최종 통계 요약 (객체 수 기준) ===\")\n",
    "        logger.info(f\"원본 총 객체 수: {sum(original_obj_counts)}개\")\n",
    "        logger.info(f\"증강 후 총 객체 수 (출력 파일 분석): {sum(final_obj_counts)}개\")\n",
    "        for c_name_log in classes:\n",
    "            o_cnt_log, f_cnt_log = self.original_class_counts.get(c_name_log,0), final_counts_from_output.get(c_name_log,0)\n",
    "            inc_str_log = f\"({(f_cnt_log-o_cnt_log)/o_cnt_log*100:.0f}%)\" if o_cnt_log > 0 else \"(원본 0)\"\n",
    "            if f_cnt_log > 0 and o_cnt_log == 0: inc_str_log = \"(신규)\"\n",
    "            logger.info(f\"  - {c_name_log}: {o_cnt_log} → {f_cnt_log} {inc_str_log}\")\n",
    "\n",
    "# 사용 예시\n",
    "if __name__ == '__main__':\n",
    "    images_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/images\"\n",
    "    labels_dir_path = \"C:/Users/USER/Desktop/증강(cutout+elastic)/Data Set version 1/train/labels\"\n",
    "    output_dir_path_base = \"C:/Users/USER/Desktop/증강(cutout+elastic)/augmented_output\"\n",
    "    \n",
    "    # 클래스 이름 설정 (예시)\n",
    "    class_names_config=['ac', 'lc', 'pc', 'tc', 'ph']\n",
    "\n",
    "    # 원본 이미지 862장을 기준으로, 약 3배인 2586장을 목표로 설정\n",
    "    target_total_images_for_experiment = 2586 \n",
    "\n",
    "    # --- 실행할 단일 파이프라인 및 블렌드 모드 설정 ---\n",
    "    # elastic_grid_first를 선택하면 apply_geometric_transform 내부에서 Cutout이 Elastic/Grid보다 먼저 실행됩니다.\n",
    "    chosen_pipeline_type = \"elastic_grid_first\" \n",
    "    chosen_blend_mode = \"simple_alpha\" # 기본 블렌딩 모드로 설정\n",
    "\n",
    "    logger.info(f\"\\n\\n{'='*20} 단일 증강 실험 시작 {'='*20}\")\n",
    "    logger.info(f\"파이프라인 유형: {chosen_pipeline_type}\")\n",
    "    logger.info(f\"블렌드 모드: {chosen_blend_mode}\")\n",
    "\n",
    "    # 해당 실험 결과만 저장할 폴더 경로 설정 (단일 실험이므로 output_dir_path_base를 직접 사용)\n",
    "    output_dir_single_exp = Path(output_dir_path_base) \n",
    "    logger.info(f\"출력 폴더: {output_dir_single_exp}\")\n",
    "    \n",
    "    pipeline_single = OptimizedYOLOAugmentation(\n",
    "        images_dir=images_dir_path, labels_dir=labels_dir_path,\n",
    "        output_dir=str(output_dir_single_exp), class_names=class_names_config\n",
    "    )\n",
    "    pipeline_single.augment_dataset_pipeline(\n",
    "        pipeline_type=chosen_pipeline_type, \n",
    "        target_total_images=target_total_images_for_experiment, \n",
    "        elastic_grid_prob=0.7, # apply_geometric_transform 내 Cutout 및 Elastic/Grid에 적용될 확률\n",
    "        copy_paste_prob=0.8, \n",
    "        num_pastes_range=(1, 3), \n",
    "        blend_mode=chosen_blend_mode \n",
    "    )\n",
    "\n",
    "    logger.info(f\"\\n\\n단일 증강 실험 완료: {chosen_pipeline_type} / {chosen_blend_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5c78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
